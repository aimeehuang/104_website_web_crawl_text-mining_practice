{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# webdriver連線:chrome要更新到最新版本\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from pyquery import PyQuery as pq \n",
    "from bs4 import BeautifulSoup\n",
    "from bs4 import SoupStrainer\n",
    "import time\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extracting job link/ job title/ company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### jobs =[]\n",
    "for i in range(1,150):\n",
    "    page_link =  \"https://www.104.com.tw/jobs/search/?ro=1&kwop=1&keyword=data%20analyst%20data%20engineer%20%20data%20scientist%20數據&page=\"+str(i)+\"&mode=s\"\n",
    "    try:\n",
    "        get_job_content(page_link)\n",
    "    except:\n",
    "        print(i+\" :error\")\n",
    "        continue\n",
    "    print(i)\n",
    "df = pd.DataFrame(columns=['jobno','title', 'company','link'], data=jobs) \n",
    "#df.to_csv(\"104_job_description_rest_v1_1122.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(df.drop_duplicates())\n",
    "df.to_csv(\"104_job_title_data_v2_1121.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#讀進excel資料\n",
    "df = pd.read_excel('104_job_title_data_rest_1122.xlsx', sheetname='Sheet 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parsing each job and get jon requirement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.104.com.tw/job/?jobno=5fd8verror\n",
      "https://www.104.com.tw/job/?jobno=6apgnerror\n",
      "https://www.104.com.tw/job/?jobno=61ijqerror\n",
      "https://www.104.com.tw/job/?jobno=6149werror\n"
     ]
    }
   ],
   "source": [
    "#跑網頁資料\n",
    "df['job_description'] = df.apply (lambda row: get_job_description(row['link']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_job_content(page_link):\n",
    "    \n",
    "    r = requests.get(page_link)\n",
    "    soupStrainer = SoupStrainer(id=\"js-job-content\")\n",
    "    soup=  BeautifulSoup(r.text,'html.parser', parse_only=soupStrainer)\n",
    "    #找到目標元素\n",
    "    contents = soup.findAll('article')\n",
    "    #print(contents)\n",
    "    #剖析輪開款式及對應型號\n",
    "    for content in contents:\n",
    "        title = content.findAll('a',{'class':'js-job-link'})[0].text\n",
    "        if 'Data' in title or '數據' in title or 'data' in title or '資料' in title:\n",
    "            link = content.findAll('a',{'class':'js-job-link'})[0]['href']\n",
    "            jobno_extract = re.search(r'(?<=jobno=)(.+)(&)',link)\n",
    "            jobno =jobno.group(1)\n",
    "            company = content['data-cust-name']\n",
    "            domain = \"https://www.104.com.tw/job/?jobno=\"\n",
    "            thisjob=[]\n",
    "            thisjob.append(jobno)\n",
    "            thisjob.append(title)\n",
    "            thisjob.append(company)\n",
    "            thisjob.append(domain+str(jobno))\n",
    "            jobs.append(thisjob)\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_job_description(link):\n",
    "    \n",
    "    try:\n",
    "        #print(link)\n",
    "        chromedriver = \"C:\\webdriver\\chromedriver\"\n",
    "        driver = webdriver.Chrome(chromedriver)\n",
    "        driver.get(link)\n",
    "        time.sleep(2) \n",
    "        soupStrainer = SoupStrainer('main', {'class': \"main\"})\n",
    "        time.sleep(2) \n",
    "        driver.find_element_by_class_name('content')\n",
    "        soup=  BeautifulSoup(driver.page_source,'html.parser',parse_only=soupStrainer)\n",
    "        contents = soup.findAll('div',{'class':'content'})\n",
    "        description = contents[0].findAll('p')[0].text.strip()\n",
    "        requirement = contents[1].findAll('dd')[-1].text.strip()+\" \"+contents[1].findAll('dd')[-2].text.strip()+\" \"+contents[1].findAll('dd')[-3].text.strip() \n",
    "        driver.quit()\n",
    "        return description +\" \"+requirement \n",
    "     \n",
    "    except:\n",
    "        driver.quit()\n",
    "        print(link+\"error\")\n",
    "        return(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jobno</th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>link</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67mbz</td>\n",
       "      <td>2019研發替代役-數據分析師</td>\n",
       "      <td>中國人壽保險股份有限公司(總公司)</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=67mbz</td>\n",
       "      <td>1. 異質資料庫數據整合 \\n2. 數據分析、應用之相關程式(C#或VB.Net或Pytho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6eh33</td>\n",
       "      <td>【EC-行】-網站數據行銷企劃師</td>\n",
       "      <td>台灣知識庫股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6eh33</td>\n",
       "      <td>1.以行銷角度規劃電子商務各大網站、APP。\\n2.提升網站使用者體驗。\\n3.具有數據分析...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63g6u</td>\n",
       "      <td>【信義房屋】資深數據工程師(Data Engineer) (熟悉數據平台建置佳)</td>\n",
       "      <td>信義房屋仲介股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=63g6u</td>\n",
       "      <td>#新團隊擴編徵才，專職大數據整合加值與創新服務應用，歡迎對數據分析有熱情，期盼數據應用落地的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5kp7k</td>\n",
       "      <td>台北數據中心-營業管理專員</td>\n",
       "      <td>旺旺集團_宜蘭食品工業股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=5kp7k</td>\n",
       "      <td>1、營業單位業務數據問題匯整及追蹤管理。\\n2、統計各區域銷售成長、目標達成、產品分析等營業...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57sur</td>\n",
       "      <td>台北數據中心-數據分析師/資料庫管理師</td>\n",
       "      <td>旺旺集團_宜蘭食品工業股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=57sur</td>\n",
       "      <td>1、匯整企業內部系統數據與外部來源數據。\\n2、清理及匯整數據流程及數據邏輯。\\n3、追蹤及...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5jwj6</td>\n",
       "      <td>Big Data Analyst / 大數據分析師</td>\n",
       "      <td>集邦科技股份有限公司_TRENDFORCE</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=5jwj6</td>\n",
       "      <td>Job Description\\nAs a Big Data Analyst, you wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e1qg</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>紅檜科技有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6e1qg</td>\n",
       "      <td>As a Data Analyst, you will be bringing techni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>66wee</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>沛星互動科技股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=66wee</td>\n",
       "      <td>Appier is a technology company that makes it e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5rm2f</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>巷語開發股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=5rm2f</td>\n",
       "      <td>In this role, you should be highly analytical ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5yevo</td>\n",
       "      <td>Big Data Visualization Engineer</td>\n",
       "      <td>台灣美光(台灣美光晶圓科技股份有限公司/台灣美光記憶體股份有限公司/美商美光亞太科技股份有限...</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=5yevo</td>\n",
       "      <td>Job Description As an Big Data Visualization E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5yevl</td>\n",
       "      <td>Big Data Engineer</td>\n",
       "      <td>台灣美光(台灣美光晶圓科技股份有限公司/台灣美光記憶體股份有限公司/美商美光亞太科技股份有限...</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=5yevl</td>\n",
       "      <td>Works with large volume of data on the Big Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2xj0b</td>\n",
       "      <td>AD30038 Data Engineer</td>\n",
       "      <td>華碩電腦股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=2xj0b</td>\n",
       "      <td>1.Familiar with relational databases, data mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6cv1g</td>\n",
       "      <td>Data Scientist/Engineer (Data Science Team)</td>\n",
       "      <td>大聯大投資控股股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6cv1g</td>\n",
       "      <td>大聯大控股資訊服務處擁有百名團隊夥伴，媲美中型軟體公司，以服務導向傾聽內外部客戶需求，結合自...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6ecm4</td>\n",
       "      <td>數據工程師（Data Engineer）</td>\n",
       "      <td>國泰金控_國泰金融控股股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6ecm4</td>\n",
       "      <td>我們正在尋找的數據工程專家，將負責數據工程相關的創新技術研究、概念性驗證與程式開發，依照個人...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6dfqc</td>\n",
       "      <td>數據工程師 (Data Engineer)</td>\n",
       "      <td>EZTABLE_三二三網路科技股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6dfqc</td>\n",
       "      <td>Job Description: \\n1. Develop, operate, and mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>67kk4</td>\n",
       "      <td>Full-Stack Engineer / Data scientist</td>\n",
       "      <td>技嘉科技股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=67kk4</td>\n",
       "      <td>IoT應用的視訊技術相關工作 影像處理演算法、電腦視覺演算法機器學習、深度學習(Machin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>69dkx</td>\n",
       "      <td>Data Scientist - Robotic</td>\n",
       "      <td>日本電氣香港有限公司_NEC Hong Kong Limited</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=69dkx</td>\n",
       "      <td>Duties:\\n•\\tSelecting features, building and o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5r9gh</td>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>撼訊科技股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=5r9gh</td>\n",
       "      <td>Make scientific research and analysis of suita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6f358</td>\n",
       "      <td>Data Scientist,  Singapore</td>\n",
       "      <td>Ruckus Networks_台灣博科通信系統有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6f358</td>\n",
       "      <td>Ruckus Networks, an ARRIS company, is looking ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>654gc</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>優愛德股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=654gc</td>\n",
       "      <td>*工作內容*\\n1.維護/開發 tracking 或平台服務\\n2.實作SaaS 在 clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5wait</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>華新麗華股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=5wait</td>\n",
       "      <td>1. Evaluate, design and implement highly scala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6fnfk</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>數位森林科技有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6fnfk</td>\n",
       "      <td>The hire will be responsible for expanding and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>66cvl</td>\n",
       "      <td>風場數據分析師 (Wind Farm Data Analyst)</td>\n",
       "      <td>永傳能源股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=66cvl</td>\n",
       "      <td>1.\\t參與海氣象與離岸風場相關數據分析，以統計方法協助進行資料分析，包括颱風季節等極端氣候...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4xh63</td>\n",
       "      <td>Shopee APP - Data Analyst 數據分析專員</td>\n",
       "      <td>樂購蝦皮有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=4xh63</td>\n",
       "      <td>1. 數據分析整理 \\n2. 提供決策的數據與建議\\n3. 數據整理、分析及圖表化\\n4. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5328y</td>\n",
       "      <td>Data &amp; Insights Analyst 數據洞察分析師</td>\n",
       "      <td>91APP_九易宇軒股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=5328y</td>\n",
       "      <td>工作內容：\\n從產品、銷售等層面建構完整的數據分析體系，並通過數據探索、各案分析等應用，提供...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5x9or</td>\n",
       "      <td>【信義房屋】數據分析師(Data Analyst)</td>\n",
       "      <td>信義房屋仲介股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=5x9or</td>\n",
       "      <td>#新團隊擴編徵才，專職大數據整合加值與創新服務應用，歡迎對數據分析有熱情，期盼數據應用落地的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>50vav</td>\n",
       "      <td>金融科技(Fintech)大數據/演算分析工程師</td>\n",
       "      <td>好好投資科技股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=50vav</td>\n",
       "      <td>【好好說明】\\n1.熟悉Python。 \\n2.熟類神經網路及基因演算法概念。 \\n3.懂輿...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6apex</td>\n",
       "      <td>IT- Data Engineer</td>\n",
       "      <td>台灣美光(台灣美光晶圓科技股份有限公司/台灣美光記憶體股份有限公司/美商美光亞太科技股份有限...</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6apex</td>\n",
       "      <td>Job DescriptionAs a Data Engineer at Micron Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6f84y</td>\n",
       "      <td>軟體設計工程師 - 數據採集 Senior software engineer - data...</td>\n",
       "      <td>買力科技有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6f84y</td>\n",
       "      <td>Job duty:\\nDevelops software to be able to sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6f84n</td>\n",
       "      <td>軟體設計工程師 - 數據解析 Senior software engineer - data...</td>\n",
       "      <td>買力科技有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6f84n</td>\n",
       "      <td>Job duty: Build the core parsing functionality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5zi1u</td>\n",
       "      <td>Machine Learning Data Scientist (Taipei)</td>\n",
       "      <td>英屬開曼群島商鼎峰智能股份有限公司台灣分公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=5zi1u</td>\n",
       "      <td>1. Use machine learning and analytical techniq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>697oo</td>\n",
       "      <td>Data Scientist 資料科學家</td>\n",
       "      <td>新加坡商鈦坦科技股份有限公司台灣分公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=697oo</td>\n",
       "      <td>●\\tWork with product owners to identify opport...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6c3kt</td>\n",
       "      <td>Machine Learning Data Scientist (Hsinchu)</td>\n",
       "      <td>英屬開曼群島商鼎峰智能股份有限公司台灣分公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6c3kt</td>\n",
       "      <td>1. Use machine learning and analytical techniq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6c3wf</td>\n",
       "      <td>[資訊部] Data Scientist</td>\n",
       "      <td>酷遊天股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6c3wf</td>\n",
       "      <td>Minimum qualifications:\\n1. Master degree in m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4gpfx</td>\n",
       "      <td>RD20275 Data Scientist (Machine Learning)</td>\n",
       "      <td>華碩電腦股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=4gpfx</td>\n",
       "      <td>1. Build and improve machine learning models t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6e0xw</td>\n",
       "      <td>T3901 Big Data Sr. Analyst/大數據資深分析師(Familiar w...</td>\n",
       "      <td>遠傳電信股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6e0xw</td>\n",
       "      <td>1. Evaluate, design and implement highly scala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6emjw</td>\n",
       "      <td>數據平台專業人員- Data Analyst(集團合作相關業務)</td>\n",
       "      <td>國泰金控_國泰金融控股股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6emjw</td>\n",
       "      <td>1.分析前的數據清洗、處理、特徵探索、以及統計、機器/深度學習模型的建立與參數優化2.與數據...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5vwwq</td>\n",
       "      <td>[RD] Data Engineer</td>\n",
       "      <td>天堂遊戲有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=5vwwq</td>\n",
       "      <td>1. 資料結構以及資料庫的建立與維護。\\n2. 資料處理系統之設計。\\n3. 資料分析與最佳...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>6alkp</td>\n",
       "      <td>[KKStream] Data Engineer</td>\n",
       "      <td>願境網訊股份有限公司_KKBOX</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6alkp</td>\n",
       "      <td>About KKStreamKKStream  is a KKBOX branch esta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>69b0t</td>\n",
       "      <td>Machine Learning/Data Engineer</td>\n",
       "      <td>香港商雅虎資訊股份有限公司(Yahoo!奇摩)</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=69b0t</td>\n",
       "      <td>A Little About UsYahoo! is a brand of Oath. Oa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>6dvq5</td>\n",
       "      <td>Data Engineer (Python)</td>\n",
       "      <td>優愛德股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6dvq5</td>\n",
       "      <td>工作內容\\n1、維護/開發 tracking 或平台服務 \\n2、實作SaaS 在 clou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6dxgi</td>\n",
       "      <td>[KKBOX] Data Engineer</td>\n",
       "      <td>願境網訊股份有限公司_KKBOX</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6dxgi</td>\n",
       "      <td>KKBOX is looking for talents to build the next...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5d7sw</td>\n",
       "      <td>Senior Software Engineer, Data</td>\n",
       "      <td>泰鼎網路安全科技有限公司_Nexusguard Limited</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=5d7sw</td>\n",
       "      <td>Nexusguard is seeking a data engineer that wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6f402</td>\n",
       "      <td>3DI PWF PI Data Engineer</td>\n",
       "      <td>台灣美光(台灣美光晶圓科技股份有限公司/台灣美光記憶體股份有限公司/美商美光亞太科技股份有限...</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6f402</td>\n",
       "      <td>Job Description：. Work close with the PI, RDA ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>6egy6</td>\n",
       "      <td>商業資料分析師 Business Data Analyst</td>\n",
       "      <td>阿福股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6egy6</td>\n",
       "      <td>1. Discover/Extract insights which could poten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5fd8v</td>\n",
       "      <td>資深數據分析師</td>\n",
       "      <td>宏燁資訊股份有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=5fd8v</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>6apgn</td>\n",
       "      <td>IT Data Engineer - DevOPS - Taichung</td>\n",
       "      <td>台灣美光(台灣美光晶圓科技股份有限公司/台灣美光記憶體股份有限公司/美商美光亞太科技股份有限...</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6apgn</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>61ijq</td>\n",
       "      <td>大數據工程師 / 架構師 / 科學家</td>\n",
       "      <td>台灣萬和科技有限公司</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=61ijq</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>6149w</td>\n",
       "      <td>ICL_Data scientist and software engineer(E1)</td>\n",
       "      <td>工研院 _財團法人工業技術研究院</td>\n",
       "      <td>https://www.104.com.tw/job/?jobno=6149w</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    jobno                                              title  \\\n",
       "0   67mbz                                    2019研發替代役-數據分析師   \n",
       "1   6eh33                                   【EC-行】-網站數據行銷企劃師   \n",
       "2   63g6u           【信義房屋】資深數據工程師(Data Engineer) (熟悉數據平台建置佳)   \n",
       "3   5kp7k                                      台北數據中心-營業管理專員   \n",
       "4   57sur                                台北數據中心-數據分析師/資料庫管理師   \n",
       "5   5jwj6                          Big Data Analyst / 大數據分析師   \n",
       "6   6e1qg                                       Data Analyst   \n",
       "7   66wee                                       Data Analyst   \n",
       "8   5rm2f                                       Data Analyst   \n",
       "9   5yevo                    Big Data Visualization Engineer   \n",
       "10  5yevl                                  Big Data Engineer   \n",
       "11  2xj0b                              AD30038 Data Engineer   \n",
       "12  6cv1g        Data Scientist/Engineer (Data Science Team)   \n",
       "13  6ecm4                               數據工程師（Data Engineer）   \n",
       "14  6dfqc                              數據工程師 (Data Engineer)   \n",
       "15  67kk4               Full-Stack Engineer / Data scientist   \n",
       "16  69dkx                           Data Scientist - Robotic   \n",
       "17  5r9gh                                Lead Data Scientist   \n",
       "18  6f358                         Data Scientist,  Singapore   \n",
       "19  654gc                                      Data Engineer   \n",
       "20  5wait                                      Data Engineer   \n",
       "21  6fnfk                                      Data Engineer   \n",
       "22  66cvl                   風場數據分析師 (Wind Farm Data Analyst)   \n",
       "23  4xh63                   Shopee APP - Data Analyst 數據分析專員   \n",
       "24  5328y                    Data & Insights Analyst 數據洞察分析師   \n",
       "25  5x9or                          【信義房屋】數據分析師(Data Analyst)   \n",
       "26  50vav                           金融科技(Fintech)大數據/演算分析工程師   \n",
       "27  6apex                                  IT- Data Engineer   \n",
       "28  6f84y  軟體設計工程師 - 數據採集 Senior software engineer - data...   \n",
       "29  6f84n  軟體設計工程師 - 數據解析 Senior software engineer - data...   \n",
       "30  5zi1u           Machine Learning Data Scientist (Taipei)   \n",
       "31  697oo                               Data Scientist 資料科學家   \n",
       "32  6c3kt          Machine Learning Data Scientist (Hsinchu)   \n",
       "33  6c3wf                               [資訊部] Data Scientist   \n",
       "34  4gpfx          RD20275 Data Scientist (Machine Learning)   \n",
       "35  6e0xw  T3901 Big Data Sr. Analyst/大數據資深分析師(Familiar w...   \n",
       "36  6emjw                   數據平台專業人員- Data Analyst(集團合作相關業務)   \n",
       "37  5vwwq                                 [RD] Data Engineer   \n",
       "38  6alkp                           [KKStream] Data Engineer   \n",
       "39  69b0t                     Machine Learning/Data Engineer   \n",
       "40  6dvq5                             Data Engineer (Python)   \n",
       "41  6dxgi                              [KKBOX] Data Engineer   \n",
       "42  5d7sw                     Senior Software Engineer, Data   \n",
       "43  6f402                           3DI PWF PI Data Engineer   \n",
       "44  6egy6                      商業資料分析師 Business Data Analyst   \n",
       "45  5fd8v                                            資深數據分析師   \n",
       "46  6apgn               IT Data Engineer - DevOPS - Taichung   \n",
       "47  61ijq                                 大數據工程師 / 架構師 / 科學家   \n",
       "48  6149w       ICL_Data scientist and software engineer(E1)   \n",
       "\n",
       "                                              company  \\\n",
       "0                                   中國人壽保險股份有限公司(總公司)   \n",
       "1                                         台灣知識庫股份有限公司   \n",
       "2                                        信義房屋仲介股份有限公司   \n",
       "3                                   旺旺集團_宜蘭食品工業股份有限公司   \n",
       "4                                   旺旺集團_宜蘭食品工業股份有限公司   \n",
       "5                               集邦科技股份有限公司_TRENDFORCE   \n",
       "6                                            紅檜科技有限公司   \n",
       "7                                        沛星互動科技股份有限公司   \n",
       "8                                          巷語開發股份有限公司   \n",
       "9   台灣美光(台灣美光晶圓科技股份有限公司/台灣美光記憶體股份有限公司/美商美光亞太科技股份有限...   \n",
       "10  台灣美光(台灣美光晶圓科技股份有限公司/台灣美光記憶體股份有限公司/美商美光亞太科技股份有限...   \n",
       "11                                         華碩電腦股份有限公司   \n",
       "12                                      大聯大投資控股股份有限公司   \n",
       "13                                  國泰金控_國泰金融控股股份有限公司   \n",
       "14                              EZTABLE_三二三網路科技股份有限公司   \n",
       "15                                         技嘉科技股份有限公司   \n",
       "16                   日本電氣香港有限公司_NEC Hong Kong Limited   \n",
       "17                                         撼訊科技股份有限公司   \n",
       "18                       Ruckus Networks_台灣博科通信系統有限公司   \n",
       "19                                          優愛德股份有限公司   \n",
       "20                                         華新麗華股份有限公司   \n",
       "21                                         數位森林科技有限公司   \n",
       "22                                         永傳能源股份有限公司   \n",
       "23                                           樂購蝦皮有限公司   \n",
       "24                                   91APP_九易宇軒股份有限公司   \n",
       "25                                       信義房屋仲介股份有限公司   \n",
       "26                                       好好投資科技股份有限公司   \n",
       "27  台灣美光(台灣美光晶圓科技股份有限公司/台灣美光記憶體股份有限公司/美商美光亞太科技股份有限...   \n",
       "28                                           買力科技有限公司   \n",
       "29                                           買力科技有限公司   \n",
       "30                             英屬開曼群島商鼎峰智能股份有限公司台灣分公司   \n",
       "31                                新加坡商鈦坦科技股份有限公司台灣分公司   \n",
       "32                             英屬開曼群島商鼎峰智能股份有限公司台灣分公司   \n",
       "33                                          酷遊天股份有限公司   \n",
       "34                                         華碩電腦股份有限公司   \n",
       "35                                         遠傳電信股份有限公司   \n",
       "36                                  國泰金控_國泰金融控股股份有限公司   \n",
       "37                                           天堂遊戲有限公司   \n",
       "38                                   願境網訊股份有限公司_KKBOX   \n",
       "39                            香港商雅虎資訊股份有限公司(Yahoo!奇摩)   \n",
       "40                                          優愛德股份有限公司   \n",
       "41                                   願境網訊股份有限公司_KKBOX   \n",
       "42                    泰鼎網路安全科技有限公司_Nexusguard Limited   \n",
       "43  台灣美光(台灣美光晶圓科技股份有限公司/台灣美光記憶體股份有限公司/美商美光亞太科技股份有限...   \n",
       "44                                           阿福股份有限公司   \n",
       "45                                         宏燁資訊股份有限公司   \n",
       "46  台灣美光(台灣美光晶圓科技股份有限公司/台灣美光記憶體股份有限公司/美商美光亞太科技股份有限...   \n",
       "47                                         台灣萬和科技有限公司   \n",
       "48                                   工研院 _財團法人工業技術研究院   \n",
       "\n",
       "                                       link  \\\n",
       "0   https://www.104.com.tw/job/?jobno=67mbz   \n",
       "1   https://www.104.com.tw/job/?jobno=6eh33   \n",
       "2   https://www.104.com.tw/job/?jobno=63g6u   \n",
       "3   https://www.104.com.tw/job/?jobno=5kp7k   \n",
       "4   https://www.104.com.tw/job/?jobno=57sur   \n",
       "5   https://www.104.com.tw/job/?jobno=5jwj6   \n",
       "6   https://www.104.com.tw/job/?jobno=6e1qg   \n",
       "7   https://www.104.com.tw/job/?jobno=66wee   \n",
       "8   https://www.104.com.tw/job/?jobno=5rm2f   \n",
       "9   https://www.104.com.tw/job/?jobno=5yevo   \n",
       "10  https://www.104.com.tw/job/?jobno=5yevl   \n",
       "11  https://www.104.com.tw/job/?jobno=2xj0b   \n",
       "12  https://www.104.com.tw/job/?jobno=6cv1g   \n",
       "13  https://www.104.com.tw/job/?jobno=6ecm4   \n",
       "14  https://www.104.com.tw/job/?jobno=6dfqc   \n",
       "15  https://www.104.com.tw/job/?jobno=67kk4   \n",
       "16  https://www.104.com.tw/job/?jobno=69dkx   \n",
       "17  https://www.104.com.tw/job/?jobno=5r9gh   \n",
       "18  https://www.104.com.tw/job/?jobno=6f358   \n",
       "19  https://www.104.com.tw/job/?jobno=654gc   \n",
       "20  https://www.104.com.tw/job/?jobno=5wait   \n",
       "21  https://www.104.com.tw/job/?jobno=6fnfk   \n",
       "22  https://www.104.com.tw/job/?jobno=66cvl   \n",
       "23  https://www.104.com.tw/job/?jobno=4xh63   \n",
       "24  https://www.104.com.tw/job/?jobno=5328y   \n",
       "25  https://www.104.com.tw/job/?jobno=5x9or   \n",
       "26  https://www.104.com.tw/job/?jobno=50vav   \n",
       "27  https://www.104.com.tw/job/?jobno=6apex   \n",
       "28  https://www.104.com.tw/job/?jobno=6f84y   \n",
       "29  https://www.104.com.tw/job/?jobno=6f84n   \n",
       "30  https://www.104.com.tw/job/?jobno=5zi1u   \n",
       "31  https://www.104.com.tw/job/?jobno=697oo   \n",
       "32  https://www.104.com.tw/job/?jobno=6c3kt   \n",
       "33  https://www.104.com.tw/job/?jobno=6c3wf   \n",
       "34  https://www.104.com.tw/job/?jobno=4gpfx   \n",
       "35  https://www.104.com.tw/job/?jobno=6e0xw   \n",
       "36  https://www.104.com.tw/job/?jobno=6emjw   \n",
       "37  https://www.104.com.tw/job/?jobno=5vwwq   \n",
       "38  https://www.104.com.tw/job/?jobno=6alkp   \n",
       "39  https://www.104.com.tw/job/?jobno=69b0t   \n",
       "40  https://www.104.com.tw/job/?jobno=6dvq5   \n",
       "41  https://www.104.com.tw/job/?jobno=6dxgi   \n",
       "42  https://www.104.com.tw/job/?jobno=5d7sw   \n",
       "43  https://www.104.com.tw/job/?jobno=6f402   \n",
       "44  https://www.104.com.tw/job/?jobno=6egy6   \n",
       "45  https://www.104.com.tw/job/?jobno=5fd8v   \n",
       "46  https://www.104.com.tw/job/?jobno=6apgn   \n",
       "47  https://www.104.com.tw/job/?jobno=61ijq   \n",
       "48  https://www.104.com.tw/job/?jobno=6149w   \n",
       "\n",
       "                                      job_description  \n",
       "0   1. 異質資料庫數據整合 \\n2. 數據分析、應用之相關程式(C#或VB.Net或Pytho...  \n",
       "1   1.以行銷角度規劃電子商務各大網站、APP。\\n2.提升網站使用者體驗。\\n3.具有數據分析...  \n",
       "2   #新團隊擴編徵才，專職大數據整合加值與創新服務應用，歡迎對數據分析有熱情，期盼數據應用落地的...  \n",
       "3   1、營業單位業務數據問題匯整及追蹤管理。\\n2、統計各區域銷售成長、目標達成、產品分析等營業...  \n",
       "4   1、匯整企業內部系統數據與外部來源數據。\\n2、清理及匯整數據流程及數據邏輯。\\n3、追蹤及...  \n",
       "5   Job Description\\nAs a Big Data Analyst, you wi...  \n",
       "6   As a Data Analyst, you will be bringing techni...  \n",
       "7   Appier is a technology company that makes it e...  \n",
       "8   In this role, you should be highly analytical ...  \n",
       "9   Job Description As an Big Data Visualization E...  \n",
       "10  Works with large volume of data on the Big Dat...  \n",
       "11  1.Familiar with relational databases, data mod...  \n",
       "12  大聯大控股資訊服務處擁有百名團隊夥伴，媲美中型軟體公司，以服務導向傾聽內外部客戶需求，結合自...  \n",
       "13  我們正在尋找的數據工程專家，將負責數據工程相關的創新技術研究、概念性驗證與程式開發，依照個人...  \n",
       "14  Job Description: \\n1. Develop, operate, and mo...  \n",
       "15  IoT應用的視訊技術相關工作 影像處理演算法、電腦視覺演算法機器學習、深度學習(Machin...  \n",
       "16  Duties:\\n•\\tSelecting features, building and o...  \n",
       "17  Make scientific research and analysis of suita...  \n",
       "18  Ruckus Networks, an ARRIS company, is looking ...  \n",
       "19  *工作內容*\\n1.維護/開發 tracking 或平台服務\\n2.實作SaaS 在 clo...  \n",
       "20  1. Evaluate, design and implement highly scala...  \n",
       "21  The hire will be responsible for expanding and...  \n",
       "22  1.\\t參與海氣象與離岸風場相關數據分析，以統計方法協助進行資料分析，包括颱風季節等極端氣候...  \n",
       "23  1. 數據分析整理 \\n2. 提供決策的數據與建議\\n3. 數據整理、分析及圖表化\\n4. ...  \n",
       "24  工作內容：\\n從產品、銷售等層面建構完整的數據分析體系，並通過數據探索、各案分析等應用，提供...  \n",
       "25  #新團隊擴編徵才，專職大數據整合加值與創新服務應用，歡迎對數據分析有熱情，期盼數據應用落地的...  \n",
       "26  【好好說明】\\n1.熟悉Python。 \\n2.熟類神經網路及基因演算法概念。 \\n3.懂輿...  \n",
       "27  Job DescriptionAs a Data Engineer at Micron Te...  \n",
       "28  Job duty:\\nDevelops software to be able to sch...  \n",
       "29  Job duty: Build the core parsing functionality...  \n",
       "30  1. Use machine learning and analytical techniq...  \n",
       "31  ●\\tWork with product owners to identify opport...  \n",
       "32  1. Use machine learning and analytical techniq...  \n",
       "33  Minimum qualifications:\\n1. Master degree in m...  \n",
       "34  1. Build and improve machine learning models t...  \n",
       "35  1. Evaluate, design and implement highly scala...  \n",
       "36  1.分析前的數據清洗、處理、特徵探索、以及統計、機器/深度學習模型的建立與參數優化2.與數據...  \n",
       "37  1. 資料結構以及資料庫的建立與維護。\\n2. 資料處理系統之設計。\\n3. 資料分析與最佳...  \n",
       "38  About KKStreamKKStream  is a KKBOX branch esta...  \n",
       "39  A Little About UsYahoo! is a brand of Oath. Oa...  \n",
       "40  工作內容\\n1、維護/開發 tracking 或平台服務 \\n2、實作SaaS 在 clou...  \n",
       "41  KKBOX is looking for talents to build the next...  \n",
       "42  Nexusguard is seeking a data engineer that wil...  \n",
       "43  Job Description：. Work close with the PI, RDA ...  \n",
       "44  1. Discover/Extract insights which could poten...  \n",
       "45                                                     \n",
       "46                                                     \n",
       "47                                                     \n",
       "48                                                     "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "#import jieba\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# job description text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     jobno                                              title  \\\n",
      "0    6fk31                                            資料倉儲架構師   \n",
      "1    687h2                                Data Engineer (DED)   \n",
      "2    65saw                               (LTEG) Data Engineer   \n",
      "3    5jh6a                              Data Engineer / 資料工程師   \n",
      "4    62y4m                                          大數據工程師/主管   \n",
      "5    60zih                              Data Analyst ( 資料分析師）   \n",
      "6    4susr                                           大數據專案工程師   \n",
      "7    4xhq8                                          市場/數據分析人員   \n",
      "8    6cgv3            Big Data Engineer_Group related vacancy   \n",
      "9    6e98l                     Data Analyst (contractor 派遣人員)   \n",
      "10   6fep8  Data Analyst at a multinational financial serv...   \n",
      "11   6egy6                      商業資料分析師 Business Data Analyst   \n",
      "12   6fpnp                               資料分析師 (Data Analyst)   \n",
      "13   5t9f1             (Senior) Clinical Data Analyst_CRO_826   \n",
      "14   4chkh                              【數銀】數位分析 Data Analyst   \n",
      "15   647h9  30561_Senior Manufacturing Performance Analyst...   \n",
      "16   5ngy4  [2018研發替代役] Data analyst/scientist (資料分析/資料科學家...   \n",
      "17   4fwzp            RRS180221-Data Analysts巨量數據分析與學習研究員(高雄)   \n",
      "18   6evkk                                 IDC Data Developer   \n",
      "19   6fhlo                             Data Center Technician   \n",
      "20   4rnm2                               Data Center Operator   \n",
      "21   5miyh                              Head of Data Analysis   \n",
      "22   5za2l                    Assistant Data Insights Manager   \n",
      "23   5x4a0                              Clinical Data Manager   \n",
      "24   54mjr                                 Big Data Analytics   \n",
      "25   5c88z                          Data Analytics Specialist   \n",
      "26   6dzye                             Data Center Technician   \n",
      "27   5flh3                             Data Scientist / 資料科學家   \n",
      "28   5ohu5                                      台北數據中心-經營分析主管   \n",
      "29   66fh7                  Java 人工智慧工程師(Java Data Engineer )   \n",
      "..     ...                                                ...   \n",
      "576  654gc                                      Data Engineer   \n",
      "577  5wait                                      Data Engineer   \n",
      "578  6fnfk                                      Data Engineer   \n",
      "579  66cvl                   風場數據分析師 (Wind Farm Data Analyst)   \n",
      "580  4xh63                   Shopee APP - Data Analyst 數據分析專員   \n",
      "581  5328y                    Data & Insights Analyst 數據洞察分析師   \n",
      "582  5x9or                          【信義房屋】數據分析師(Data Analyst)   \n",
      "583  50vav                           金融科技(Fintech)大數據/演算分析工程師   \n",
      "584  6apex                                  IT- Data Engineer   \n",
      "585  6f84y  軟體設計工程師 - 數據採集 Senior software engineer - data...   \n",
      "586  6f84n  軟體設計工程師 - 數據解析 Senior software engineer - data...   \n",
      "587  5zi1u           Machine Learning Data Scientist (Taipei)   \n",
      "588  697oo                               Data Scientist 資料科學家   \n",
      "589  6c3kt          Machine Learning Data Scientist (Hsinchu)   \n",
      "590  6c3wf                               [資訊部] Data Scientist   \n",
      "591  4gpfx          RD20275 Data Scientist (Machine Learning)   \n",
      "592  6e0xw  T3901 Big Data Sr. Analyst/大數據資深分析師(Familiar w...   \n",
      "593  6emjw                   數據平台專業人員- Data Analyst(集團合作相關業務)   \n",
      "594  5vwwq                                 [RD] Data Engineer   \n",
      "595  6alkp                           [KKStream] Data Engineer   \n",
      "596  69b0t                     Machine Learning/Data Engineer   \n",
      "597  6dvq5                             Data Engineer (Python)   \n",
      "598  6dxgi                              [KKBOX] Data Engineer   \n",
      "599  5d7sw                     Senior Software Engineer, Data   \n",
      "600  6f402                           3DI PWF PI Data Engineer   \n",
      "601  6egy6                      商業資料分析師 Business Data Analyst   \n",
      "602  5fd8v                                            資深數據分析師   \n",
      "603  6apgn               IT Data Engineer - DevOPS - Taichung   \n",
      "604  61ijq                                 大數據工程師 / 架構師 / 科學家   \n",
      "605  6149w       ICL_Data scientist and software engineer(E1)   \n",
      "\n",
      "                                               company  \\\n",
      "0                                         勤業眾信聯合會計師事務所   \n",
      "1                                           孚創雲端股份有限公司   \n",
      "2                               LINE Taiwan_台灣連線股份有限公司   \n",
      "3                                         瑞嘉軟體科技股份有限公司   \n",
      "4                                           旭曜資訊服務有限公司   \n",
      "5                                   美商勞倫斯科技股份有限公司台灣分公司   \n",
      "6                            SAGE TECHNOLOGIES LIMITED   \n",
      "7                                           昆盈企業股份有限公司   \n",
      "8                                         長新生醫國際股份有限公司   \n",
      "9                                  德商默克在台集團_台灣默克股份有限公司   \n",
      "10                                     萬寶華企業管理顧問股份有限公司   \n",
      "11                                            阿福股份有限公司   \n",
      "12                                          智域國際股份有限公司   \n",
      "13               經緯智庫股份有限公司 (MGR Consulting Co., Ltd.)   \n",
      "14                                國泰世華商業銀行股份有限公司_人力資源部   \n",
      "15                                      台灣康寧顯示玻璃股份有限公司   \n",
      "16                    宏達電 HTC Corporation_宏達國際電子股份有限公司   \n",
      "17                                          緯創資通股份有限公司   \n",
      "18                                      香港商奧東有限公司台灣分公司   \n",
      "19                                   Google_美商科高國際有限公司   \n",
      "20                                   Atos_台灣源訊科技股份有限公司   \n",
      "21                                  In Touch Games Ltd   \n",
      "22                             香港商雅虎資訊股份有限公司(Yahoo!奇摩)   \n",
      "23                                        佳生科技顧問股份有限公司   \n",
      "24                                            雲派科技有限公司   \n",
      "25                                            裕利股份有限公司   \n",
      "26                                   Google_美商科高國際有限公司   \n",
      "27                               集邦科技股份有限公司_TRENDFORCE   \n",
      "28                                   旺旺集團_宜蘭食品工業股份有限公司   \n",
      "29                                          聚力國際咨詢有限公司   \n",
      "..                                                 ...   \n",
      "576                                          優愛德股份有限公司   \n",
      "577                                         華新麗華股份有限公司   \n",
      "578                                         數位森林科技有限公司   \n",
      "579                                         永傳能源股份有限公司   \n",
      "580                                           樂購蝦皮有限公司   \n",
      "581                                   91APP_九易宇軒股份有限公司   \n",
      "582                                       信義房屋仲介股份有限公司   \n",
      "583                                       好好投資科技股份有限公司   \n",
      "584  台灣美光(台灣美光晶圓科技股份有限公司/台灣美光記憶體股份有限公司/美商美光亞太科技股份有限...   \n",
      "585                                           買力科技有限公司   \n",
      "586                                           買力科技有限公司   \n",
      "587                             英屬開曼群島商鼎峰智能股份有限公司台灣分公司   \n",
      "588                                新加坡商鈦坦科技股份有限公司台灣分公司   \n",
      "589                             英屬開曼群島商鼎峰智能股份有限公司台灣分公司   \n",
      "590                                          酷遊天股份有限公司   \n",
      "591                                         華碩電腦股份有限公司   \n",
      "592                                         遠傳電信股份有限公司   \n",
      "593                                  國泰金控_國泰金融控股股份有限公司   \n",
      "594                                           天堂遊戲有限公司   \n",
      "595                                   願境網訊股份有限公司_KKBOX   \n",
      "596                            香港商雅虎資訊股份有限公司(Yahoo!奇摩)   \n",
      "597                                          優愛德股份有限公司   \n",
      "598                                   願境網訊股份有限公司_KKBOX   \n",
      "599                    泰鼎網路安全科技有限公司_Nexusguard Limited   \n",
      "600  台灣美光(台灣美光晶圓科技股份有限公司/台灣美光記憶體股份有限公司/美商美光亞太科技股份有限...   \n",
      "601                                           阿福股份有限公司   \n",
      "602                                         宏燁資訊股份有限公司   \n",
      "603  台灣美光(台灣美光晶圓科技股份有限公司/台灣美光記憶體股份有限公司/美商美光亞太科技股份有限...   \n",
      "604                                         台灣萬和科技有限公司   \n",
      "605                                   工研院 _財團法人工業技術研究院   \n",
      "\n",
      "                                        link  \\\n",
      "0    https://www.104.com.tw/job/?jobno=6fk31   \n",
      "1    https://www.104.com.tw/job/?jobno=687h2   \n",
      "2    https://www.104.com.tw/job/?jobno=65saw   \n",
      "3    https://www.104.com.tw/job/?jobno=5jh6a   \n",
      "4    https://www.104.com.tw/job/?jobno=62y4m   \n",
      "5    https://www.104.com.tw/job/?jobno=60zih   \n",
      "6    https://www.104.com.tw/job/?jobno=4susr   \n",
      "7    https://www.104.com.tw/job/?jobno=4xhq8   \n",
      "8    https://www.104.com.tw/job/?jobno=6cgv3   \n",
      "9    https://www.104.com.tw/job/?jobno=6e98l   \n",
      "10   https://www.104.com.tw/job/?jobno=6fep8   \n",
      "11   https://www.104.com.tw/job/?jobno=6egy6   \n",
      "12   https://www.104.com.tw/job/?jobno=6fpnp   \n",
      "13   https://www.104.com.tw/job/?jobno=5t9f1   \n",
      "14   https://www.104.com.tw/job/?jobno=4chkh   \n",
      "15   https://www.104.com.tw/job/?jobno=647h9   \n",
      "16   https://www.104.com.tw/job/?jobno=5ngy4   \n",
      "17   https://www.104.com.tw/job/?jobno=4fwzp   \n",
      "18   https://www.104.com.tw/job/?jobno=6evkk   \n",
      "19   https://www.104.com.tw/job/?jobno=6fhlo   \n",
      "20   https://www.104.com.tw/job/?jobno=4rnm2   \n",
      "21   https://www.104.com.tw/job/?jobno=5miyh   \n",
      "22   https://www.104.com.tw/job/?jobno=5za2l   \n",
      "23   https://www.104.com.tw/job/?jobno=5x4a0   \n",
      "24   https://www.104.com.tw/job/?jobno=54mjr   \n",
      "25   https://www.104.com.tw/job/?jobno=5c88z   \n",
      "26   https://www.104.com.tw/job/?jobno=6dzye   \n",
      "27   https://www.104.com.tw/job/?jobno=5flh3   \n",
      "28   https://www.104.com.tw/job/?jobno=5ohu5   \n",
      "29   https://www.104.com.tw/job/?jobno=66fh7   \n",
      "..                                       ...   \n",
      "576  https://www.104.com.tw/job/?jobno=654gc   \n",
      "577  https://www.104.com.tw/job/?jobno=5wait   \n",
      "578  https://www.104.com.tw/job/?jobno=6fnfk   \n",
      "579  https://www.104.com.tw/job/?jobno=66cvl   \n",
      "580  https://www.104.com.tw/job/?jobno=4xh63   \n",
      "581  https://www.104.com.tw/job/?jobno=5328y   \n",
      "582  https://www.104.com.tw/job/?jobno=5x9or   \n",
      "583  https://www.104.com.tw/job/?jobno=50vav   \n",
      "584  https://www.104.com.tw/job/?jobno=6apex   \n",
      "585  https://www.104.com.tw/job/?jobno=6f84y   \n",
      "586  https://www.104.com.tw/job/?jobno=6f84n   \n",
      "587  https://www.104.com.tw/job/?jobno=5zi1u   \n",
      "588  https://www.104.com.tw/job/?jobno=697oo   \n",
      "589  https://www.104.com.tw/job/?jobno=6c3kt   \n",
      "590  https://www.104.com.tw/job/?jobno=6c3wf   \n",
      "591  https://www.104.com.tw/job/?jobno=4gpfx   \n",
      "592  https://www.104.com.tw/job/?jobno=6e0xw   \n",
      "593  https://www.104.com.tw/job/?jobno=6emjw   \n",
      "594  https://www.104.com.tw/job/?jobno=5vwwq   \n",
      "595  https://www.104.com.tw/job/?jobno=6alkp   \n",
      "596  https://www.104.com.tw/job/?jobno=69b0t   \n",
      "597  https://www.104.com.tw/job/?jobno=6dvq5   \n",
      "598  https://www.104.com.tw/job/?jobno=6dxgi   \n",
      "599  https://www.104.com.tw/job/?jobno=5d7sw   \n",
      "600  https://www.104.com.tw/job/?jobno=6f402   \n",
      "601  https://www.104.com.tw/job/?jobno=6egy6   \n",
      "602  https://www.104.com.tw/job/?jobno=5fd8v   \n",
      "603  https://www.104.com.tw/job/?jobno=6apgn   \n",
      "604  https://www.104.com.tw/job/?jobno=61ijq   \n",
      "605  https://www.104.com.tw/job/?jobno=6149w   \n",
      "\n",
      "                                       job_description  agil  ai  ajax  \\\n",
      "0    面對數位轉型創新的時代，勤業眾信擬定中長期計畫，建構全方位的資訊策略，並積極精進數據管理，期...     0   0     0   \n",
      "1    The Data Engineering Team is looking for talen...     0   0     0   \n",
      "2    [About this Job] \\r\\nWe are looking for a savv...     0   0     0   \n",
      "3    ‧  Design and implement software systems and t...     0   0     0   \n",
      "4    對大數據領域相關工作有熱情，自律並有以下技能與相關工作經驗者，歡迎加入我們的行列\\r\\n\\r...     0   0     0   \n",
      "5    We are looking for a software engineer who is ...     1   1     0   \n",
      "6    為了配合我們公司專業服務團隊的拓展，我們正在尋求熱誠人員，他/她將會接觸大數據專業知識(AI...     0   1     0   \n",
      "7    1.產品銷售統整分析、產品業務分析及客群分析2.各類相關統計數據彙整及報表製表3.全球市場資...     0   0     0   \n",
      "8    Everfortune.AI is established in 2018. Collabo...     0   1     0   \n",
      "9    Job Purpose:\\r\\nData analyst responsibilities ...     0   0     0   \n",
      "10   Our client is a multinational financial servic...     0   0     0   \n",
      "11                                                 NaN     0   0     0   \n",
      "12   -\\t與客戶溝通訪談確認分析需求以建立分析議題。\\r\\n1. 根據不同議題、資料來源，設計資...     0   0     0   \n",
      "13   Demonstrates full competence when conducting t...     0   0     0   \n",
      "14   【公司部門簡介 About us】\\r\\n國泰金控為臺灣服務客戶數最多的領先金融服務業者，致...     0   0     0   \n",
      "15   Position Description:\\r\\nThe Mfg. Performance ...     0   0     0   \n",
      "16   1. Analyze large, complex datasets to reveal u...     0   0     0   \n",
      "17   1. 從事data cleaning, data preprocessing, featur...     0   0     0   \n",
      "18   1. Contributes to creating Extract, Transform,...     0   0     0   \n",
      "19   Google isn't just a software company. The Hard...     0   0     0   \n",
      "20   ‧ Infrastructure 1st line support (電腦機房設備及環境巡視...     0   0     0   \n",
      "21   Job title: Head of Data Analysis - SQL\\r\\nLoca...     0   1     0   \n",
      "22   A Little About UsYahoo! is a brand of Oath. Oa...     0   0     0   \n",
      "23   1. 撰寫臨床試驗過程中所需要的文件，包含個案報告書(CRF)、資料管理計畫書(DMP)、個...     0   0     0   \n",
      "24   Develop the algorithm of Big Data Analytics su...     0   0     0   \n",
      "25   1. Support the business analytics products and...     0   0     0   \n",
      "26   Google isn't just a software company. The Hard...     0   0     0   \n",
      "27   Job Description\\r\\nWe are looking for Machine ...     0   0     0   \n",
      "28   1、協助營業單位業務數據問題匯整及提出數據整合建議。\\r\\n2、依據業務數據報表進行營業分析...     0   0     0   \n",
      "29   工作責任: 1.現有/新平台人工智能語音助理軟體研究開發;2.Data Mining , 資...     0   0     0   \n",
      "..                                                 ...   ...  ..   ...   \n",
      "576  *工作內容*\\r\\n1.維護/開發 tracking 或平台服務\\r\\n2.實作SaaS 在...     1   0     0   \n",
      "577  1. Evaluate, design and implement highly scala...     0   0     0   \n",
      "578  The hire will be responsible for expanding and...     0   0     0   \n",
      "579  1.\\t參與海氣象與離岸風場相關數據分析，以統計方法協助進行資料分析，包括颱風季節等極端氣候...     0   0     0   \n",
      "580  1. 數據分析整理 \\r\\n2. 提供決策的數據與建議\\r\\n3. 數據整理、分析及圖表化\\...     0   0     0   \n",
      "581  工作內容：\\r\\n從產品、銷售等層面建構完整的數據分析體系，並通過數據探索、各案分析等應用，...     0   0     0   \n",
      "582  #新團隊擴編徵才，專職大數據整合加值與創新服務應用，歡迎對數據分析有熱情，期盼數據應用落地的...     0   0     0   \n",
      "583  【好好說明】\\r\\n1.熟悉Python。 \\r\\n2.熟類神經網路及基因演算法概念。 \\r...     0   0     0   \n",
      "584  Job DescriptionAs a Data Engineer at Micron Te...     0   0     0   \n",
      "585  Job duty:\\r\\nDevelops software to be able to s...     1   0     0   \n",
      "586  Job duty: Build the core parsing functionality...     1   0     0   \n",
      "587  1. Use machine learning and analytical techniq...     0   0     0   \n",
      "588  ●\\tWork with product owners to identify opport...     0   0     0   \n",
      "589  1. Use machine learning and analytical techniq...     0   0     0   \n",
      "590  Minimum qualifications:\\r\\n1. Master degree in...     0   0     0   \n",
      "591  1. Build and improve machine learning models t...     0   0     0   \n",
      "592  1. Evaluate, design and implement highly scala...     0   0     0   \n",
      "593  1.分析前的數據清洗、處理、特徵探索、以及統計、機器/深度學習模型的建立與參數優化2.與數據...     0   0     0   \n",
      "594  1. 資料結構以及資料庫的建立與維護。\\r\\n2. 資料處理系統之設計。\\r\\n3. 資料分...     0   0     0   \n",
      "595  About KKStreamKKStream  is a KKBOX branch esta...     0   0     0   \n",
      "596  A Little About UsYahoo! is a brand of Oath. Oa...     0   0     0   \n",
      "597  工作內容\\r\\n1、維護/開發 tracking 或平台服務 \\r\\n2、實作SaaS 在 ...     1   0     0   \n",
      "598  KKBOX is looking for talents to build the next...     0   0     0   \n",
      "599  Nexusguard is seeking a data engineer that wil...     0   0     0   \n",
      "600  Job Description：. Work close with the PI, RDA ...     0   0     0   \n",
      "601  1. Discover/Extract insights which could poten...     0   0     0   \n",
      "602                                                NaN     0   0     0   \n",
      "603                                                NaN     0   0     0   \n",
      "604                                                NaN     0   0     0   \n",
      "605                                                NaN     0   0     0   \n",
      "\n",
      "     algorithm  amazon   ...     visual tool  warehous  watson  web  window  \\\n",
      "0            0       0   ...               0         1       0    0       0   \n",
      "1            0       0   ...               0         0       0    0       0   \n",
      "2            0       0   ...               0         0       0    0       0   \n",
      "3            0       0   ...               0         0       0    0       0   \n",
      "4            0       0   ...               0         0       0    0       0   \n",
      "5            1       0   ...               0         0       0    0       1   \n",
      "6            0       0   ...               0         0       0    0       0   \n",
      "7            0       0   ...               0         0       0    0       0   \n",
      "8            1       0   ...               0         0       0    0       0   \n",
      "9            0       0   ...               0         0       0    0       0   \n",
      "10           1       0   ...               0         0       0    0       0   \n",
      "11           0       0   ...               0         0       0    0       0   \n",
      "12           0       0   ...               0         0       0    0       0   \n",
      "13           0       0   ...               0         0       0    0       0   \n",
      "14           0       0   ...               0         0       0    0       0   \n",
      "15           0       0   ...               0         0       0    0       0   \n",
      "16           0       0   ...               0         0       0    0       0   \n",
      "17           0       0   ...               0         0       0    0       0   \n",
      "18           0       0   ...               0         0       0    1       0   \n",
      "19           0       0   ...               0         0       0    0       0   \n",
      "20           0       0   ...               0         0       0    0       1   \n",
      "21           1       0   ...               0         0       0    0       0   \n",
      "22           0       0   ...               0         0       0    0       0   \n",
      "23           0       0   ...               0         0       0    0       0   \n",
      "24           1       0   ...               0         0       0    0       0   \n",
      "25           0       0   ...               0         0       0    0       0   \n",
      "26           0       0   ...               0         0       0    0       0   \n",
      "27           0       0   ...               0         0       0    0       0   \n",
      "28           0       0   ...               0         0       0    0       0   \n",
      "29           0       0   ...               0         0       0    0       0   \n",
      "..         ...     ...   ...             ...       ...     ...  ...     ...   \n",
      "576          0       0   ...               0         0       0    0       0   \n",
      "577          0       0   ...               0         1       0    0       0   \n",
      "578          0       0   ...               0         1       0    0       0   \n",
      "579          0       0   ...               0         0       0    0       0   \n",
      "580          0       0   ...               0         0       0    0       0   \n",
      "581          0       0   ...               0         0       0    0       0   \n",
      "582          0       0   ...               0         0       0    0       0   \n",
      "583          0       0   ...               0         0       0    1       0   \n",
      "584          0       0   ...               1         1       0    0       0   \n",
      "585          1       0   ...               0         0       0    1       0   \n",
      "586          1       0   ...               0         0       0    0       0   \n",
      "587          0       0   ...               0         0       0    0       0   \n",
      "588          1       0   ...               0         0       0    0       0   \n",
      "589          0       0   ...               0         0       0    0       0   \n",
      "590          1       0   ...               1         0       0    0       0   \n",
      "591          0       0   ...               0         0       0    0       0   \n",
      "592          0       0   ...               0         1       0    0       0   \n",
      "593          0       0   ...               0         0       0    0       0   \n",
      "594          0       0   ...               0         0       0    0       0   \n",
      "595          0       0   ...               0         0       0    0       0   \n",
      "596          0       0   ...               0         0       0    0       0   \n",
      "597          0       0   ...               0         0       0    0       0   \n",
      "598          0       0   ...               1         1       0    1       0   \n",
      "599          1       0   ...               0         0       0    0       0   \n",
      "600          0       0   ...               0         0       0    0       0   \n",
      "601          0       0   ...               0         0       0    0       0   \n",
      "602          0       0   ...               0         0       0    0       0   \n",
      "603          0       0   ...               0         0       0    0       0   \n",
      "604          0       0   ...               0         0       0    0       0   \n",
      "605          0       0   ...               0         0       0    0       0   \n",
      "\n",
      "     word  wsdl  xml  yahoo  zookeep  \n",
      "0       0     0    0      0        0  \n",
      "1       0     0    0      0        0  \n",
      "2       0     0    0      0        1  \n",
      "3       0     0    0      0        0  \n",
      "4       0     0    0      0        0  \n",
      "5       0     0    0      0        0  \n",
      "6       0     0    0      0        0  \n",
      "7       0     0    0      0        0  \n",
      "8       0     0    0      0        0  \n",
      "9       0     0    0      0        0  \n",
      "10      0     0    0      0        0  \n",
      "11      0     0    0      0        0  \n",
      "12      1     0    0      0        0  \n",
      "13      1     0    0      0        0  \n",
      "14      0     0    0      0        0  \n",
      "15      0     0    0      0        0  \n",
      "16      0     0    0      0        0  \n",
      "17      0     0    0      0        0  \n",
      "18      0     1    0      0        0  \n",
      "19      0     0    0      0        0  \n",
      "20      0     0    0      0        0  \n",
      "21      0     0    0      0        0  \n",
      "22      0     0    0      1        0  \n",
      "23      1     0    0      0        0  \n",
      "24      0     0    0      0        0  \n",
      "25      0     0    0      0        0  \n",
      "26      0     0    0      0        0  \n",
      "27      0     0    0      0        0  \n",
      "28      0     0    0      0        0  \n",
      "29      0     0    0      0        0  \n",
      "..    ...   ...  ...    ...      ...  \n",
      "576     0     0    0      0        0  \n",
      "577     0     0    0      0        0  \n",
      "578     0     0    0      0        0  \n",
      "579     0     0    0      0        0  \n",
      "580     0     0    0      0        0  \n",
      "581     0     0    0      0        0  \n",
      "582     0     0    0      0        0  \n",
      "583     0     0    0      0        0  \n",
      "584     0     0    0      0        0  \n",
      "585     0     0    0      0        0  \n",
      "586     0     0    1      0        0  \n",
      "587     0     0    0      0        0  \n",
      "588     0     0    0      0        0  \n",
      "589     0     0    0      0        0  \n",
      "590     0     0    0      0        0  \n",
      "591     1     0    0      0        0  \n",
      "592     0     0    0      0        0  \n",
      "593     0     0    0      0        0  \n",
      "594     0     0    0      0        0  \n",
      "595     0     0    0      0        0  \n",
      "596     0     0    0      1        0  \n",
      "597     0     0    0      0        0  \n",
      "598     0     0    0      0        0  \n",
      "599     0     0    0      0        0  \n",
      "600     0     0    0      0        0  \n",
      "601     0     0    0      0        0  \n",
      "602     0     0    0      0        0  \n",
      "603     0     0    0      0        0  \n",
      "604     0     0    0      0        0  \n",
      "605     0     0    0      0        0  \n",
      "\n",
      "[606 rows x 354 columns]\n"
     ]
    }
   ],
   "source": [
    "#read job description file\n",
    "\n",
    "df2 = pd.read_excel('104_job_description_data_all_1122.xlsx', sheetname='Sheet 1')\n",
    "df2.set_index('jobno')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', \"a's\", 'able', 'about', 'above', 'according', 'ability', 'ability', 'advanced', 'accordingly', 'across', 'actually', 'after', 'afterwards', 'analyze', 'analyst', 'again', 'against', \"ain't\", 'all', 'allow', 'advanced', 'annual', 'allows', 'almost', 'alone', 'along', 'already', 'and', 'are', 'achieve', 'also', 'although', 'always', 'am', 'among', 'activities', 'administration', 'amongst', 'an', 'and', 'another', 'any', 'access', 'accuracy', 'actionable', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'about', 'adwords', 'anyways', 'anywhere', 'apart', 'appear', 'appreciate', 'appropriate', 'are', \"aren't\", 'around', 'as', 'aside', 'ask', 'asking', 'associated', 'at', 'assist', 'available', 'away', 'awfully', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'bring', 'before', 'beforehand', 'behind', 'being', 'believe', 'bachelor', 'below', 'beside', 'besides', 'best', 'better', 'background', 'between', 'beyond', 'both', 'brief', 'but', 'build', 'building', 'by', \"c'mon\", \"c's\", 'came', 'can', 'control', 'create', 'creating', \"can't\", 'cannot', 'cant', 'cause', 'causes', 'company', 'customers', 'certain', 'certainly', 'changes', 'clearly', 'co', 'candidate', 'communication', 'com', 'come', 'comes', 'concerning', 'consequently', 'communicate', 'communication', 'complex', 'consider', 'considering', 'contain', 'containing', 'contains', 'capabilities', 'capability', 'corresponding', 'could', \"couldn't\", 'course', 'currently', 'challenges', 'definitely', 'described', 'despite', 'did', \"didn't\", 'degree', 'description', 'different', 'do', 'does', \"doesn't\", 'doing', 'driven', 'demonstrate', 'demonstrated', 'deployment', \"don't\", 'done', 'down', 'downwards', 'during', 'define', 'deliver', 'delivery', 'decisions', 'define', 'deliver', 'delivery', 'day', 'each', 'edu', 'eg', 'eight', 'either', 'experienced', 'experiences', 'engineers', 'else', 'elsewhere', 'enough', 'entirely', 'especially', 'ensure', 'efficient', 'enable', 'et', 'etc', 'even', 'ever', 'every', 'education', 'effective', 'establish', 'everybody', 'everyone', 'everything', 'everywhere', 'ex', 'expert', 'expertise', 'exactly', 'example', 'except', 'excellent', 'far', 'few', 'fig', 'figs', 'fluent', 'focus', 'fifth', 'first', 'five', 'followed', 'following', 'familiar', 'fast', 'follows', 'for', 'former', 'formerly', 'forth', 'field', 'full', 'facilitate', 'four', 'from', 'further', 'furthermore', 'get', 'failiar', 'familiarity', 'gets', 'getting', 'given', 'gives', 'go', 'group', 'groups', 'goes', 'going', 'gone', 'got', 'gotten', 'good', 'governance', 'great', 'growing', 'greetings', 'had', \"hadn't\", 'happens', 'hardly', 'has', \"hasn't\", 'have', \"haven't\", 'having', 'he', \"he's\", 'hello', 'help', 'hence', 'high', 'highly', 'her', 'here', \"here's\", 'hereafter', 'hereby', 'herein', 'hereupon', 'hers', 'herself', 'hi', 'him', 'himself', 'his', 'hither', 'hopefully', 'how', 'howbeit', 'however', \"i'd\", \"i'll\", \"i'm\", \"i've\", 'ie', 'if', 'ignored', 'isnt', 'isn', 'independently', 'immediate', 'in', 'inasmuch', 'inc', 'indeed', 'implementation', 'improve', 'including', 'industry', 'indicate', 'indicated', 'indicates', 'inner', 'insofar', 'instead', 'into', 'inward', 'is', \"isn't\", 'include', 'includes', 'identify', 'implement', 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'job', 'issues', 'implementing', 'improvement', 'itself', 'just', 'keep', 'keeps', 'kept', 'know', 'known', 'knows', 'last', 'lately', 'kkbox', 'knowledge', 'later', 'latter', 'latterly', 'least', 'less', 'lest', 'let', \"let's\", 'like', 'liked', 'love', 'likely', 'little', 'look', 'looking', 'looks', 'line', 'learn', 'ltd', 'mainly', 'many', 'may', 'maybe', 'master', 'maintain', 'maintenance', 'me', 'mean', 'meanwhile', 'merely', 'might', 'meet', 'methods', 'multiple', 'more', 'moreover', 'most', 'mostly', 'much', 'minimum', 'make', 'making', 'meeting', 'members', 'major', 'manage', 'market', 'managers', 'must', 'my', 'myself', 'name', 'namely', 'nd', 'near', 'nearly', 'necessary', 'need', 'nan', 'needs', 'neither', 'never', 'nevertheless', 'new', 'next', 'nine', 'no', 'nobody', 'needed', 'none', 'noone', 'nor', 'normally', 'not', 'nothing', 'novel', 'now', 'nowhere', 'obviously', 'of', 'off', 'often', 'oh', 'ok', 'okay', 'old', 'on', 'once', 'one', 'organization', 'outlook', 'ones', 'only', 'onto', 'or', 'other', 'others', 'otherwise', 'ought', 'our', 'ours', 'ourselves', 'out', 'outside', 'over', 'overall', 'operating', 'operations', 'opportunities', 'optimize', 'own', 'particular', 'particularly', 'per', 'perhaps', 'pervious', 'preferred', 'perform', 'practices', 'problem', 'problem skills', 'problems', 'processes', 'part', 'participate', 'passion', 'process', 'processes', 'policies', 'portfolio', 'position', 'product', 'products', 'professional', 'proficiency', 'proficient', 'proven', 'provide', 'partners', 'passionate', 'placed', 'please', 'plus', 'possible', 'presumably', 'project', 'projects', 'prob,lems', 'people', 'probably', 'provides', 'que', 'quite', 'qv', 'qualifications', 'quality', 'qualification', 'rather', 'rd', 're', 'really', 'reasonably', 'required', 'requirements', 'research', 'responsibilities', 'responsible', 'review', 'results', 'relavant', 'regarding', 'regardless', 'regards', 'relatively', 'respectively', 'reporting', 'related', 'reports', 'requirement', 'resolution', 'resolve', 'responsibility', 'role', 'roles', 'reliable', 'relationship', 'right', 'said', 'same', 'saw', 'say', 'saying', 'says', 'second', 'secondly', 'see', 'service', 'support', 'seeing', 'seem', 'seemed', 'seeming', 'seems', 'select', 'seen', 'self', 'selves', 'sensible', 'sent', 'set', 'sets', 'serious', 'seriously', 'seven', 'several', 'shall', 'solid', 'solution', 'solutions', 'she', 'should', \"shouldn't\", 'since', 'six', 'solve', 'so', 'some', 'somebody', 'somehow', 'someone', 'something', 'sometime', 'sometimes', 'somewhat', 'somewhere', 'solving', 'soon', 'sorry', 'specified', 'specify', 'specifying', 'still', 'sub', 'such', 'sup', 'sure', 'skill', 'skills', \"t's\", 'take', 'taken', 'tell', 'tends', 'th', 'than', 'thank', 'thanks', 'thanx', 'that', \"that's\", 'thats', 'the', 'their', 'thereon', 'theirs', 'them', 'themselves', 'then', 'thence', 'thereof', 'there', \"there's\", 'thereafter', 'thereby', 'therefore', 'therein', 'theres', 'thereupon', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'think', 'this', 'third', 'this', 'thorough', 'thoroughly', 'those', 'tw', 'though', 'three', 'through', 'throughout', 'thru', 'taiwan', 'thus', 'to', 'together', 'too', 'took', 'tasks', 'team', 'teams', 'technical', 'techniques', 'technologies', 'technology', 'time', 'toward', 'towards', 'tried', 'tries', 'truly', 'troubleshoot', 'troubleshooting', 'try', 'trying', 'twice', 'two', 'un', 'under', 'unfortunately', 'unless', 'unlikely', 'until', 'unto', 'up', 'upon', 'us', 'use', 'used', 'useful', 'uses', 'using', 'usually', 'understand', 'understanding', 'value', 'various', 'very', 'via', 'viz', 'verbal', 'vs', 'want', 'wants', 'was', \"wasn't\", 'way', 'we', \"we'd\", \"we'll\", \"we're\", \"we've\", 'welcome', 'well', 'went', 'were', \"weren't\", 'what', \"what's\", 'whatever', 'when', 'whence', 'whenever', 'where', \"where's\", 'whereafter', 'whereas', 'whereby', 'wherein', 'whereupon', 'wherever', 'whether', 'which', 'while', 'whither', 'who', 'write', \"who's\", 'whoever', 'whole', 'whom', 'whose', 'www', 'why', 'will', 'willing', 'wish', 'with', 'world', 'within', 'without', \"won't\", 'wonder', 'would', 'writing', 'written', 'work', 'working', \"wouldn't\", 'yes', 'yet', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yez', 'years', 'year', 'yourself', 'yourselves', 'zero', 'job']\n"
     ]
    }
   ],
   "source": [
    "#list of stopwords, could add or delete depending on the result of the list.\n",
    "\n",
    "stopwords=[\"a\",\"a's\",\"able\",\"about\",\"above\",\"according\",'ability','ability', 'advanced',\n",
    "\"accordingly\",\"across\",\"actually\",\"after\",\"afterwards\",'analyze','analyst',\n",
    "\"again\",\"against\",\"ain't\",\"all\",\"allow\",'advanced','annual',\n",
    "\"allows\",\"almost\",\"alone\",\"along\",\"already\",\"and\",\"are\",'achieve',\n",
    "\"also\",\"although\",\"always\",\"am\",\"among\",'activities', 'administration',\n",
    "\"amongst\",\"an\",\"and\",\"another\",\"any\",'access', 'accuracy', 'actionable', \n",
    "\"anybody\",\"anyhow\",\"anyone\",\"anything\",\"anyway\",\"about\",'adwords',\n",
    "\"anyways\",\"anywhere\",\"apart\",\"appear\",\"appreciate\",\n",
    "\"appropriate\",\"are\",\"aren't\",\"around\",\"as\",\n",
    "\"aside\",\"ask\",\"asking\",\"associated\",\"at\",'assist',\n",
    "\"available\",\"away\",\"awfully\",\"be\",\"became\",\n",
    "\"because\",\"become\",\"becomes\",\"becoming\",\"been\",'bring',\n",
    "\"before\",\"beforehand\",\"behind\",\"being\",\"believe\",'bachelor',\n",
    "\"below\",\"beside\",\"besides\",\"best\",\"better\",'background',\n",
    "\"between\",\"beyond\",\"both\",\"brief\",\"but\",'build', 'building',\n",
    "\"by\",\"c'mon\",\"c's\",\"came\",\"can\",'control', 'create', 'creating', \n",
    "\"can't\",\"cannot\",\"cant\",\"cause\",\"causes\",'company','customers',\n",
    "\"certain\",\"certainly\",\"changes\",\"clearly\",\"co\",'candidate','communication',\n",
    "\"com\",\"come\",\"comes\",\"concerning\",\"consequently\",'communicate', 'communication', 'complex',\n",
    "\"consider\",\"considering\",\"contain\",\"containing\",\"contains\",\n",
    "'capabilities', 'capability',\n",
    "\"corresponding\",\"could\",\"couldn't\",\"course\",\"currently\", 'challenges',\n",
    "\"definitely\",\"described\",\"despite\",\"did\",\"didn't\",\"degree\",\"description\",\n",
    "\"different\",\"do\",\"does\",\"doesn't\",\"doing\",'driven','demonstrate', 'demonstrated', 'deployment',\n",
    "\"don't\",\"done\",\"down\",\"downwards\",\"during\",'define', 'deliver', 'delivery',\n",
    "'decisions',  'define', 'deliver', 'delivery', 'day',\n",
    "\"each\",\"edu\",\"eg\",\"eight\",\"either\", 'experienced', 'experiences','engineers',\n",
    "\"else\",\"elsewhere\",\"enough\",\"entirely\",\"especially\",'ensure', 'efficient','enable',\n",
    "\"et\",\"etc\",\"even\",\"ever\",\"every\", 'education', 'effective','establish',\n",
    "\"everybody\",\"everyone\",\"everything\",\"everywhere\",\"ex\",'expert', 'expertise',\n",
    "\"exactly\",\"example\",\"except\",'excellent',\"far\",\"few\",\"fig\",\"figs\",'fluent', 'focus',\n",
    "\"fifth\",\"first\",\"five\",\"followed\",\"following\",'familiar', 'fast',\n",
    "\"follows\",\"for\",\"former\",\"formerly\",\"forth\",'field','full','facilitate',\n",
    "\"four\",\"from\",\"further\",\"furthermore\",\"get\",'failiar', 'familiarity',\n",
    "\"gets\",\"getting\",\"given\",\"gives\",\"go\",'group', 'groups',\n",
    "\"goes\",\"going\",\"gone\",\"got\",\"gotten\",'good', 'governance', 'great', 'growing', \n",
    "\"greetings\",\"had\",\"hadn't\",\"happens\",\"hardly\",\n",
    "\"has\",\"hasn't\",\"have\",\"haven't\",\"having\",\n",
    "\"he\",\"he's\",\"hello\",\"help\",\"hence\",'high', 'highly',\n",
    "\"her\",\"here\",\"here's\",\"hereafter\",\"hereby\",\n",
    "\"herein\",\"hereupon\",\"hers\",\"herself\",\"hi\",\n",
    "\"him\",\"himself\",\"his\",\"hither\",\"hopefully\",\n",
    "\"how\",\"howbeit\",\"however\",\"i'd\",\"i'll\",\n",
    "\"i'm\",\"i've\",\"ie\",\"if\",\"ignored\",\"isnt\",\"isn\",'independently',\n",
    "\"immediate\",\"in\",\"inasmuch\",\"inc\",\"indeed\",'implementation', 'improve','including', 'industry',\n",
    "\"indicate\",\"indicated\",\"indicates\",\"inner\",\"insofar\",\n",
    "\"instead\",\"into\",\"inward\",\"is\",\"isn't\",\"include\", \"includes\",'identify','implement',\n",
    "\"it\",\"it'd\",\"it'll\",\"it's\",\"its\",\"job\",'issues','implementing', 'improvement', \n",
    "\"itself\",\"just\",\"keep\",\"keeps\",\"kept\",\n",
    "\"know\",\"known\",\"knows\",\"last\",\"lately\",\"kkbox\", 'knowledge',\n",
    "\"later\",\"latter\",\"latterly\",\"least\",\"less\",\n",
    "\"lest\",\"let\",\"let's\",\"like\",\"liked\",'love',\n",
    "\"likely\",\"little\",\"look\",\"looking\",\"looks\",\"line\",'learn',\n",
    "\"ltd\",\"mainly\",\"many\",\"may\",\"maybe\",\"master\", 'maintain', 'maintenance',\n",
    "\"me\",\"mean\",\"meanwhile\",\"merely\",\"might\",'meet', 'methods','multiple',\n",
    "\"more\",\"moreover\",\"most\",\"mostly\",\"much\",'minimum','make', 'making',\n",
    "'meeting', 'members', 'major', 'manage','market', 'managers',\n",
    "\"must\",\"my\",\"myself\",\"name\",\"namely\",\n",
    "\"nd\",\"near\",\"nearly\",\"necessary\",\"need\",\"nan\",\n",
    "\"needs\",\"neither\",\"never\",\"nevertheless\",\"new\",\n",
    "\"next\",\"nine\",\"no\",\"nobody\",'needed',\n",
    "\"none\",\"noone\",\"nor\",\"normally\",\"not\",\n",
    "\"nothing\",\"novel\",\"now\",\"nowhere\",\"obviously\",\n",
    "\"of\",\"off\",\"often\",\"oh\",\"ok\",\n",
    "\"okay\",\"old\",\"on\",\"once\",\"one\",'organization', 'outlook',\n",
    "\"ones\",\"only\",\"onto\",\"or\",\"other\",\n",
    "\"others\",\"otherwise\",\"ought\",\"our\",\"ours\",\n",
    "\"ourselves\",\"out\",\"outside\",\"over\",\"overall\",'operating', 'operations', 'opportunities', 'optimize', \n",
    "\"own\",\"particular\",\"particularly\",\"per\",\"perhaps\",\"pervious\",'preferred','perform',\n",
    "'practices', 'problem', 'problem skills', 'problems','processes',\n",
    "'part', 'participate', 'passion','process', 'processes','policies', 'portfolio', 'position',\n",
    "'product', 'products', 'professional', 'proficiency', 'proficient','proven', 'provide',\n",
    "'partners', 'passionate',           \n",
    "\"placed\",\"please\",\"plus\",\"possible\",\"presumably\",\"project\",\"projects\",'prob,lems','people',\n",
    "\"probably\",\"provides\",\"que\",\"quite\",\"qv\",'qualifications', 'quality', 'qualification', \n",
    "\"rather\",\"rd\",\"re\",\"really\",\"reasonably\",'required', 'requirements', 'research',\n",
    "'responsibilities','responsible', 'review',  'results','relavant',\n",
    "\"regarding\",\"regardless\",\"regards\",\"relatively\",\"respectively\",'reporting','related',\n",
    "'reports', 'requirement', 'resolution', 'resolve', 'responsibility', \n",
    "'role', 'roles','reliable','relationship',\n",
    "\"right\",\"said\",\"same\",\"saw\",\"say\",\n",
    "\"saying\",\"says\",\"second\",\"secondly\",\"see\",\"service\",\"support\",\n",
    "\"seeing\",\"seem\",\"seemed\",\"seeming\",\"seems\",\"select\",\n",
    "\"seen\",\"self\",\"selves\",\"sensible\",\"sent\", 'set', 'sets',\n",
    "\"serious\",\"seriously\",\"seven\",\"several\",\"shall\",'solid', 'solution', 'solutions',\n",
    "\"she\",\"should\",\"shouldn't\",\"since\",\"six\",\"solve\",\n",
    "\"so\",\"some\",\"somebody\",\"somehow\",\"someone\",\n",
    "\"something\",\"sometime\",\"sometimes\",\"somewhat\",\"somewhere\",'solving',\n",
    "\"soon\",\"sorry\",\"specified\",\"specify\",\"specifying\",\n",
    "\"still\",\"sub\",\"such\",\"sup\",\"sure\",'skill', 'skills',\n",
    "\"t's\",\"take\",\"taken\",\"tell\",\"tends\",\n",
    "\"th\",\"than\",\"thank\",\"thanks\",\"thanx\",\n",
    "\"that\",\"that's\",\"thats\",\"the\",\"their\",\"thereon\",\n",
    "\"theirs\",\"them\",\"themselves\",\"then\",\"thence\",\"thereof\",\n",
    "\"there\",\"there's\",\"thereafter\",\"thereby\",\"therefore\",\n",
    "\"therein\",\"theres\",\"thereupon\",\"these\",\"they\",\n",
    "\"they'd\",\"they'll\",\"they're\",\"they've\",\"think\",\"this\",\n",
    "\"third\",\"this\",\"thorough\",\"thoroughly\",\"those\",'tw',\n",
    "\"though\",\"three\",\"through\",\"throughout\",\"thru\",'taiwan',\n",
    "\"thus\",\"to\",\"together\",\"too\",\"took\",'tasks', 'team', 'teams', 'technical',\n",
    "'techniques', 'technologies', 'technology','time',\n",
    "\"toward\",\"towards\",\"tried\",\"tries\",\"truly\",'troubleshoot', 'troubleshooting', \n",
    "\"try\",\"trying\",\"twice\",\"two\",\"un\",\n",
    "\"under\",\"unfortunately\",\"unless\",\"unlikely\",\"until\",\n",
    "\"unto\",\"up\",\"upon\",\"us\",\"use\",\n",
    "\"used\",\"useful\",\"uses\",\"using\",\"usually\",'understand', 'understanding',\n",
    "\"value\",\"various\",\"very\",\"via\",\"viz\",'verbal',\n",
    "\"vs\",\"want\",\"wants\",\"was\",\"wasn't\",\n",
    "\"way\",\"we\",\"we'd\",\"we'll\",\"we're\",\n",
    "\"we've\",\"welcome\",\"well\",\"went\",\"were\",\n",
    "\"weren't\",\"what\",\"what's\",\"whatever\",\"when\",\n",
    "\"whence\",\"whenever\",\"where\",\"where's\",\"whereafter\",\n",
    "\"whereas\",\"whereby\",\"wherein\",\"whereupon\",\"wherever\",\n",
    "\"whether\",\"which\",\"while\",\"whither\",\"who\",'write',\n",
    "\"who's\",\"whoever\",\"whole\",\"whom\",\"whose\",'www',\n",
    "\"why\",\"will\",\"willing\",\"wish\",\"with\",'world',\n",
    "\"within\",\"without\",\"won't\",\"wonder\",\"would\",\"writing\",\"written\",\"work\",\"working\",\n",
    "\"wouldn't\",\"yes\",\"yet\",\"you\",\"you'd\",\n",
    "\"you'll\",\"you're\",\"you've\",\"your\",\"yours\",\"yez\",\"years\",\"year\",\n",
    "\"yourself\",\"yourselves\",\"zero\",\"job\"]\n",
    "print(stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_tools = ['agile', 'ai', 'ajax', 'algorithm' , 'amazon', 'analysis',  'analytic',\n",
    "                 'analytics', 'apache', 'api', 'app', 'application', 'athena',\n",
    "                 'artificial intelligence', 'asp', 'automate', 'automation',\n",
    "                 'aws', 'azure', 'angularjs', \n",
    "                 'bi', 'big data', 'business intelligence','bigquery',\n",
    "                 'caffe', 'cassandra', 'cdm', 'ci', 'cleaning', 'client' 'cloud', \n",
    "                 'cloud platform', 'coding', 'collaborate', 'collaboration', 'collaborative', 'collect', \n",
    "                 'collection', 'computer science','c',\n",
    "                 'crf', 'crm', 'cognos' ,'cloudera','clinic','csdn','cuda',\n",
    "                 'cross functional', 'css','chatbot',\n",
    "                 'data', 'data analysis', 'data analytic', 'data analytics', 'data center', 'data collection', \n",
    "                 'data engineer', 'data engineering', 'data insights', 'data management','d js',\n",
    "                 'data mart', 'data mining', 'data modeling', 'data pipeline', 'data pipelines', \n",
    "                 'data platform', 'data processing', 'data science', 'data scientist', 'data scientists', \n",
    "                 'data services', 'data source', 'data sources', 'data systems', \n",
    "                 'data tools', 'data visualization', 'data warehouse', 'database', 'databases', \n",
    "                 'datasets', 'db', 'deep learning','dmp','django','design pattern',\n",
    "                 'diagram', 'digital', 'distributed systems', 'docker', 'documentation', 'debian', \n",
    "                 'ecosystem',  'elasticsearch', 'engineer','emr',\n",
    "                 'engineering', 'english',  'enterprise', 'economics',\n",
    "                 'equipment', 'erp', 'etl', 'etl ms','excel', 'extract', \n",
    "                 'facebook', 'finance', 'financial', 'flume',\n",
    "                 'gcp', 'git', 'github', 'global', 'google', 'google analytics', 'google cloud','ggplot','gpu','glue','go',\n",
    "                 'hadoop', 'hadoop ecosystem', \n",
    "                 'hardware', 'hbase', 'hdfs', 'hive',\n",
    "                 'html',  'http', 'https', 'hdfs',\n",
    "                 'innovation','innovative', 'insight', 'insights','image processing','image recognition',\n",
    "                 'intelligence','iot', 'ip','impala','information management',\n",
    "                 'java','jvm', 'jdbc',\n",
    "                 'javascript', 'join', 'jquery', 'js', 'json', 'kafka', 'keras','knime','kaggle','kinesis', 'kibana',\n",
    "                 'large scale', 'leadership', 'lambda','linux', 'logstash',\n",
    "                 'linux',  'll', 'machine learning', \n",
    "                 'maintaining', 'management', \n",
    "                 'manager', 'manner', 'mapreduce', 'marketing', 'mart','minitab',\n",
    "                 'math', 'mathematical', 'mathematics', 'matlab', 'metrics',\n",
    "                 'micron', 'microsoft', 'mining', 'mining machine', 'ml', 'mobile', 'model',\n",
    "                 'modeling', 'models', 'mongodb', 'monitor', 'monitoring', \n",
    "                 'ms sql', 'mssql', 'multi', 'mysql', 'natural', 'numpy','neural network',\n",
    "                 'natural language', 'net', 'network','nodejs','node js',\n",
    "                 'networks', 'nlp', 'nosql', 'office','odbc','olap',\n",
    "                 'open source', 'operate', 'operation', 'operational', 'optimizing', 'ods',\n",
    "                 'oracle', 'osp', 'pandas',  \n",
    "                 'perl', 'php', 'physical', 'pipeline', 'pipelines',\n",
    "                 'pl', 'pl sql', 'platform', 'platforms','plotly',\n",
    "                 'pm', 'postgresql','power bi', 'powerpoint',\n",
    "                 'predictive', 'present', 'presentation','pytorch',' powebi',\n",
    "                 'presentations', 'procedures', 'processing',\n",
    "                 'protocol', 'python', 'quantitative', 'query','qlikview', 'rdbms', \n",
    "                 'redis', 'relational', 'relational database','react',\n",
    "                 'report', 'restful', 'risk', 'rwd','r','ruby','rails','redshift','redash', \n",
    "                 'sap', 'sas', 'sas spss', 'scala', 'scalable', 'scale','soap','social analysis',\n",
    "                 'scikit', 'script', 'scripting','stored procedure',\n",
    "                 'scrum', 'search', 'security', 'serve', 'server', 'services', 'shell','ssis', \n",
    "                 'site', 'social', 'software', 'software development', 'software engineering','spark',  \n",
    "                 'spring', 'spss', 'sql','sql server', 'staff', \n",
    "                 'statistical', 'statistics', 'statistics experience', 'storage', 'storm', \n",
    "                 'strategic', 'strategy', 'streaming', 'streams', \n",
    "                 'survey', 'svn', 'system','svm',\n",
    "                 'tableau', 'tensorflow', 'test', 'testing', 'text mining', 'teradata',\n",
    "                 'toeic','t sql', 'tuning', 'unix', 'user experience', 'ubuntu','ui', 'ux','vue','vba',\n",
    "                 'visual', 'visualization', 'visualization tools', 'warehouse', 'web',  'windows', \n",
    "                 'word','watson', 'wsdl','xml', 'yahoo', 'zookeeper']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                                    ...\n",
      "1      The Data Engineering Team is looking for talen...\n",
      "2       About this Job    We are looking for a savvy ...\n",
      "3         Design and implement software systems and t...\n",
      "4                                                    ...\n",
      "5      We are looking for a software engineer who is ...\n",
      "6                                                  AI...\n",
      "7                                                    ...\n",
      "8      Everfortune AI is established in    Collaborat...\n",
      "9      Job Purpose   Data analyst responsibilities in...\n",
      "10     Our client is a multinational financial servic...\n",
      "11                                                   nan\n",
      "12                                                   ...\n",
      "13     Demonstrates full competence when conducting t...\n",
      "14             About us                              ...\n",
      "15     Position Description   The Mfg  Performance An...\n",
      "16        Analyze large  complex datasets to reveal u...\n",
      "17          data cleaning  data preprocessing  featur...\n",
      "18        Contributes to creating Extract  Transform ...\n",
      "19     Google isn t just a software company  The Hard...\n",
      "20       Infrastructure  st line support             ...\n",
      "21     Job title  Head of Data Analysis   SQL  Locati...\n",
      "22     A Little About UsYahoo  is a brand of Oath  Oa...\n",
      "23                                CRF          DMP   ...\n",
      "24     Develop the algorithm of Big Data Analytics su...\n",
      "25        Support the business analytics products and...\n",
      "26     Google isn t just a software company  The Hard...\n",
      "27     Job Description  We are looking for Machine Le...\n",
      "28                                                   ...\n",
      "29                                    Data Mining    ...\n",
      "                             ...                        \n",
      "576                    tracking            SaaS   clo...\n",
      "577       Evaluate  design and implement highly scala...\n",
      "578    The hire will be responsible for expanding and...\n",
      "579                                                  ...\n",
      "580                                                  ...\n",
      "581                                                  ...\n",
      "582                                                  ...\n",
      "583                Python                            ...\n",
      "584    Job DescriptionAs a Data Engineer at Micron Te...\n",
      "585    Job duty   Develops software to be able to sch...\n",
      "586    Job duty  Build the core parsing functionality...\n",
      "587       Use machine learning and analytical techniq...\n",
      "588      Work with product owners to identify opportu...\n",
      "589       Use machine learning and analytical techniq...\n",
      "590    Minimum qualifications      Master degree in m...\n",
      "591       Build and improve machine learning models t...\n",
      "592       Evaluate  design and implement highly scala...\n",
      "593                                                  ...\n",
      "594                                                  ...\n",
      "595    About KKStreamKKStream  is a KKBOX branch esta...\n",
      "596    A Little About UsYahoo  is a brand of Oath  Oa...\n",
      "597                  tracking             SaaS   clou...\n",
      "598    KKBOX is looking for talents to build the next...\n",
      "599    Nexusguard is seeking a data engineer that wil...\n",
      "600    Job Description   Work close with the PI  RDA ...\n",
      "601       Discover Extract insights which could poten...\n",
      "602                                                  nan\n",
      "603                                                  nan\n",
      "604                                                  nan\n",
      "605                                                  nan\n",
      "Name: jd_rc, Length: 606, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#remove chinese/digit/. from jd context\n",
    "\n",
    "jd_rc = []\n",
    "for i in df2['job_description']:\n",
    "    rc = remove_Chinese(str(i))\n",
    "    jd_rc.append(rc)\n",
    "df2['jd_rc']=jd_rc\n",
    "print(df2['jd_rc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_Chinese(context):\n",
    "    filter_chinese = re.compile(u'[\\u4e00-\\u9fa5]') # Chinese unicode range\n",
    "    filter_symbol = re.compile(r'[^\\w]') #remove symbol\n",
    "    filter_num = re.compile(r'[0-9]+')\n",
    "    context_fc = filter_chinese.sub(r' ',context) # remove all non-Chinese characters\n",
    "    context_fs = filter_symbol.sub(r' ',context_fc)\n",
    "    context_fin = context_fs.encode('utf-8').decode()# convert unicode back to str\n",
    "    context_fn=  filter_num.sub(r' ', context_fin)\n",
    "    return context_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stemSentence(sentence):\n",
    "    porter = PorterStemmer()\n",
    "    token_words=word_tokenize(sentence)\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "            word_stem= porter.stem(word)+\" \"\n",
    "            #word_stem_strip = word_stem.strip(\" \")\n",
    "            stem_sentence.append(word_stem)\n",
    "            stem_sentence.append(\"\")\n",
    "    return \"\".join(stem_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get important feaure by using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['agile', 'ai', 'ai ai', 'ajax', 'algorithm', 'algorithms', 'amazon', 'analysis', 'analysis business', 'analysis data', 'analytic', 'analytical', 'analytics', 'analyzing', 'apache', 'api', 'app', 'application', 'applications', 'applied', 'apply', 'architect', 'architecture', 'architectures', 'area', 'areas', 'art', 'artificial', 'artificial intelligence', 'asp', 'asp net', 'assigned', 'audit', 'automate', 'automation', 'avr', 'aws', 'aws gcp', 'azure', 'based', 'basic', 'behavior', 'bi', 'big', 'big data', 'brands', 'bs', 'business', 'business data', 'business intelligence', 'caffe', 'call', 'career', 'cassandra', 'cdm', 'center', 'chain', 'ci', 'cleaning', 'client', 'clients', 'clinical', 'closely', 'cloud', 'cloud platform', 'code', 'coding', 'collaborate', 'collaboration', 'collaborative', 'collect', 'collection', 'components', 'computer', 'computer science', 'computing', 'concepts', 'conduct', 'continuous', 'contribute', 'core', 'creation', 'creative', 'crf', 'critical', 'crm', 'cross', 'cross functional', 'css', 'css javascript', 'current', 'customer', 'data', 'data analysis', 'data analytic', 'data analytics', 'data center', 'data collection', 'data data', 'data engineer', 'data engineering', 'data insights', 'data management', 'data mart', 'data mining', 'data modeling', 'data pipeline', 'data pipelines', 'data platform', 'data processing', 'data science', 'data scientist', 'data scientists', 'data services', 'data source', 'data sources', 'data statistical', 'data systems', 'data tools', 'data visualization', 'data warehouse', 'database', 'databases', 'datasets', 'db', 'decision', 'deep', 'deep learning', 'depth', 'design', 'design data', 'design development', 'designing', 'desired', 'develop', 'develop data', 'developers', 'developing', 'development', 'development data', 'development experience', 'devops', 'diagram', 'digital', 'distributed', 'distributed systems', 'docker', 'documentation', 'domain', 'drive', 'ecosystem', 'edge', 'effectively', 'efficiency', 'elasticsearch', 'end', 'engineer', 'engineering', 'english', 'enhance', 'enterprise', 'environment', 'environments', 'equipment', 'equivalent', 'erp', 'etl', 'etl ms', 'evaluate', 'excel', 'excel powerpoint', 'excel word', 'execute', 'execution', 'existing', 'experience', 'experience big', 'experience data', 'experience experience', 'experience hadoop', 'experience large', 'experience nosql', 'external', 'extract', 'extracting', 'facebook', 'features', 'fields', 'finance', 'financial', 'fit', 'flow', 'format', 'framework', 'frameworks', 'functional', 'functions', 'gcp', 'git', 'github', 'global', 'google', 'google analytics', 'google cloud', 'hadoop', 'hadoop ecosystem', 'hadoop hive', 'hadoop spark', 'hands', 'hands experience', 'hardware', 'hbase', 'hdfs', 'hive', 'hive spark', 'html', 'html css', 'html javascript', 'http', 'https', 'id', 'ideas', 'information', 'infrastructure', 'initiatives', 'innovation', 'innovative', 'insight', 'insights', 'installation', 'integrate', 'integration', 'intelligence', 'internal', 'interpersonal', 'interpret', 'iot', 'ip', 'java', 'java javascript', 'java python', 'java scala', 'java sql', 'javascript', 'join', 'jquery', 'js', 'json', 'kafka', 'keras', 'key', 'language', 'languages', 'large', 'large scale', 'lead', 'leadership', 'learning', 'learning algorithms', 'learning deep', 'learning models', 'level', 'life', 'lifecycle', 'linux', 'linux java', 'linux python', 'linux shell', 'linux unix', 'll', 'machine', 'machine learning', 'maintaining', 'management', 'management data', 'management systems', 'manager', 'manner', 'manufacturing', 'mapreduce', 'marketing', 'mart', 'material', 'math', 'mathematical', 'mathematics', 'matlab', 'metrics', 'micron', 'microsoft', 'mining', 'mining machine', 'ml', 'mobile', 'model', 'modeling', 'models', 'mongodb', 'monitor', 'monitoring', 'motivated', 'ms', 'ms sql', 'mssql', 'multi', 'mysql', 'mysql oracle', 'natural', 'natural language', 'net', 'net python', 'network', 'networking', 'networks', 'nice', 'nlp', 'nosql', 'nosql database', 'office', 'online', 'open', 'open source', 'operate', 'operation', 'operational', 'optimizing', 'oracle', 'oriented', 'osp', 'outsourcing', 'pandas', 'partner', 'pattern', 'patterns', 'performance', 'perl', 'php', 'physical', 'pipeline', 'pipelines', 'pl', 'pl sql', 'plan', 'planning', 'plans', 'platform', 'platforms', 'player', 'pm', 'postgresql', 'potential', 'power', 'power bi', 'powerpoint', 'powerpoint word', 'practical', 'practical experience', 'predictive', 'present', 'presentation', 'presentations', 'procedures', 'processing', 'program', 'programming', 'programming languages', 'protocol', 'python', 'python java', 'python ms', 'python python', 'python scala', 'python spss', 'python sql', 'quantitative', 'query', 'questions', 'rdbms', 'real', 'redis', 'regulatory', 'relational', 'relational database', 'relational databases', 'relationships', 'relevant', 'relevant experience', 'report', 'restful', 'risk', 'rwd', 'salary', 'sales', 'sap', 'sas', 'sas spss', 'scala', 'scala java', 'scalable', 'scale', 'science', 'science information', 'scientist', 'scientists', 'scikit', 'script', 'scripting', 'scrum', 'search', 'security', 'senior', 'serve', 'server', 'services', 'shell', 'shell script', 'site', 'social', 'software', 'software development', 'software engineering', 'source', 'sources', 'spark', 'spark hadoop', 'spark kafka', 'specific', 'specifications', 'spring', 'spss', 'sql', 'sql data', 'sql excel', 'sql mysql', 'sql nosql', 'sql oracle', 'sql python', 'sql server', 'staff', 'stakeholders', 'standards', 'state', 'state art', 'statistical', 'statistics', 'statistics experience', 'status', 'storage', 'storm', 'strategic', 'strategies', 'strategy', 'streaming', 'streams', 'strong', 'strong analytical', 'studio', 'study', 'supply', 'supporting', 'survey', 'svn', 'system', 'systems', 'systems data', 'tableau', 'tech', 'tensorflow', 'test', 'testing', 'text', 'thinking', 'timely', 'toeic', 'tool', 'tools', 'top', 'track', 'tracking', 'training', 'transformation', 'trends', 'tuning', 'unix', 'user', 'user experience', 'users', 'ux', 'validation', 'vba', 'visual', 'visualization', 'visualization tools', 'warehouse', 'web', 'wide', 'windows', 'word', 'xml', 'yahoo']\n"
     ]
    }
   ],
   "source": [
    "#remove chinese -> tfidf(tokenize) : \n",
    "\n",
    "jd_rc_list = df2['jd_rc']\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word',stop_words=stopwords, max_features=500, vocabulary=None,ngram_range = (1,2)) \n",
    "\n",
    "vector = vectorizer.fit_transform(jd_rc_list).toarray() \n",
    "# fit_transform function create a document-term matrix(116 * 300 matrix(top 300 terms)),toarray() funtion to turn it into np array type.\n",
    "\n",
    "feature_names= vectorizer.get_feature_names()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stemming feature and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306\n",
      "['agil', 'ai', 'ajax', 'algorithm', 'amazon', 'analysi', 'analyt', 'angoss', 'angularj', 'apach', 'api', 'app', 'applic', 'artifici intellig', 'asp', 'athena', 'autom', 'aw', 'azur', 'bi', 'big data', 'bigqueri', 'block chain', 'bs', 'busi intellig', 'c', 'caff', 'cassandra', 'cdm', 'chatbot', 'ci', 'clean', 'clientcloud', 'clinic', 'cloud platform', 'cloudera', 'code', 'cogno', 'collabor', 'collect', 'comput scienc', 'crf', 'crm', 'cross function', 'csdn', 'css', 'cuda', 'd js', 'data', 'data analysi', 'data analyt', 'data center', 'data collect', 'data engin', 'data insight', 'data manag', 'data mart', 'data mine', 'data model', 'data pipelin', 'data platform', 'data process', 'data scienc', 'data scientist', 'data servic', 'data sourc', 'data statist', 'data system', 'data tool', 'data visual', 'data warehous', 'databas', 'dataset', 'db', 'debian', 'deep learn', 'design pattern', 'diagram', 'digit', 'distribut system', 'dj', 'django', 'dmp', 'docker', 'document', 'econom', 'ecosystem', 'elasticsearch', 'emr', 'engin', 'english', 'enterpris', 'equip', 'erp', 'etl', 'etl ms', 'excel', 'extract', 'facebook', 'financ', 'financi', 'flume', 'gcp', 'ggplot', 'git', 'github', 'global', 'glue', 'gohadoop', 'googl', 'googl analyt', 'googl cloud', 'gpu', 'hadoop ecosystem', 'hardwar', 'hbase', 'hdf', 'hive', 'html', 'http', 'imag process', 'imag recognit', 'impala', 'inform manag', 'innov', 'insight', 'intellig', 'iot', 'ip', 'java', 'javascript', 'jdbc', 'join', 'jqueri', 'js', 'json', 'jvm', 'kafka', 'kaggl', 'kera', 'kibana', 'kinesi', 'knime', 'lambda', 'larg scale', 'leadership', 'linux', 'll', 'logstash', 'machin learn', 'maintain', 'manag', 'manner', 'mapreduc', 'market', 'mart', 'math', 'mathemat', 'matlab', 'metric', 'micron', 'microsoft', 'mine', 'mine machin', 'minitab', 'ml', 'mobil', 'model', 'mongodb', 'monitor', 'ms', 'ms sql', 'mssql', 'multi', 'mysql', 'natur', 'natur languag', 'net', 'net python', 'network', 'network analysi', 'neural network', 'nlp', 'node js', 'nodej', 'nosql', 'numpi', 'od', 'odbc', 'offic', 'olap', 'open sourc', 'oper', 'optim', 'oracl', 'orang', 'osp', 'panda', 'perl', 'php', 'physic', 'pipelin', 'pl', 'pl sql', 'platform', 'plotli', 'pm', 'postgresql', 'powebi', 'power bi', 'powerpoint', 'predict', 'present', 'procedur', 'process', 'protocol', 'python', 'pytorch', 'qlikview', 'quantit', 'queri', 'r', 'rail', 'rapidmin', 'rdbm', 'react', 'redash', 'redi', 'redshift', 'relat', 'relat databas', 'report', 'rest', 'risk', 'rubi', 'rwd', 'sa', 'sa spss', 'salfrod', 'sap', 'scala', 'scalabl', 'scale', 'scikit', 'script', 'scrum', 'search', 'secur', 'serv', 'server', 'servic', 'shell', 'site', 'soap', 'social', 'social analysi', 'softwar', 'softwar develop', 'softwar engin', 'spark', 'spring', 'spss', 'sql', 'sql server', 'ssi', 'staff', 'stan', 'statist', 'statist experi', 'storag', 'store procedur', 'storm', 'strateg', 'strategi', 'stream', 'survey', 'svm', 'svn', 'system', 't sql', 'tableau', 'tensorflow', 'teradata', 'test', 'text mine', 'toeic', 'tune', 'ubuntu', 'ui', 'unix', 'user experi', 'ux', 'vba', 'visual', 'visual tool', 'vue', 'vuej', 'warehous', 'watson', 'web', 'window', 'word', 'wsdl', 'xml', 'yahoo', 'zookeep']\n"
     ]
    }
   ],
   "source": [
    "#stem feature\n",
    "\n",
    "feature_stem=[]\n",
    "#feature_stem.extend(feature_addition)\n",
    "for i in feature_tools: #利用已經選好的feature\n",
    "    f_stem= stemSentence(str(i))\n",
    "    feature_stem.append(f_stem.strip(' '))\n",
    "feature_stem=sorted(list(set(feature_stem)))\n",
    "print(len(feature_stem))\n",
    "print(feature_stem)\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      data mart data mart DB data warehous data qual...\n",
      "1      the data engin team is look for talent data en...\n",
      "2      about thi job We are look for a savvi data eng...\n",
      "3      design and implement softwar system and tool f...\n",
      "4                    python kera tensorflow linux python\n",
      "5      We are look for a softwar engin who is passion...\n",
      "6      AI machin learn etl hadoop python C C java nos...\n",
      "7                                                  excel\n",
      "8      everfortun AI is establish in collabor with ex...\n",
      "9      job purpos data analyst respons includ conduct...\n",
      "10     our client is a multin financi servic compani ...\n",
      "11                                                   nan\n",
      "12     machin learn excel word powerpoint python R sql D\n",
      "13     demonstr full compet when conduct the follow t...\n",
      "14     about us who we are look for what will you do ...\n",
      "15     posit descript the mfg perform analyst posit i...\n",
      "16     analyz larg complex dataset to reveal underli ...\n",
      "17     data clean data preprocess featur engin model ...\n",
      "18     contribut to creat extract transform and load ...\n",
      "19     googl isn t just a softwar compani the hardwar...\n",
      "20     infrastructur st line support applic st line s...\n",
      "21     job titl head of data analysi sql locat birmin...\n",
      "22     A littl about usyahoo is a brand of oath oath ...\n",
      "23     crf dmp deg dvp edit check edc edit check edc ...\n",
      "24     develop the algorithm of big data analyt suppo...\n",
      "25     support the busi analyt product and servic whi...\n",
      "26     googl isn t just a softwar compani the hardwar...\n",
      "27     job descript We are look for machin learn expe...\n",
      "28                                                      \n",
      "29     data mine java java multi thread nio java fram...\n",
      "                             ...                        \n",
      "576    track saa cloud servic ex aw gcp and etc leade...\n",
      "577    evalu design and implement highli scalabl data...\n",
      "578    the hire will be respons for expand and optim ...\n",
      "579                                           python sql\n",
      "580                             python sql python MS sql\n",
      "581    etl ER model sql languag store procedur etl pr...\n",
      "582    data pipelin machin learn benchmark python R s...\n",
      "583    python text mine natur languag machin learn gi...\n",
      "584    job descriptiona a data engin at micron techno...\n",
      "585    job duti develop softwar to be abl to schedul ...\n",
      "586    job duti build the core pars function of our i...\n",
      "587    use machin learn and analyt techniqu to build ...\n",
      "588    work with product owner to identifi opportun f...\n",
      "589    use machin learn and analyt techniqu to build ...\n",
      "590    minimum qualif master degre in mathemat or sta...\n",
      "591    build and improv machin learn model that class...\n",
      "592    evalu design and implement highli scalabl data...\n",
      "593    xgboost K mean al naiv bay lda python R sql st...\n",
      "594                             googl certifi profession\n",
      "595    about kkstreamkkstream is a kkbox branch estab...\n",
      "596    A littl about usyahoo is a brand of oath oath ...\n",
      "597    track saa cloud servic ex aw gcp and etc leade...\n",
      "598    kkbox is look for talent to build the next gen...\n",
      "599    nexusguard is seek a data engin that will work...\n",
      "600    job descript work close with the PI rda modul ...\n",
      "601    discov extract insight which could potenti hel...\n",
      "602                                                  nan\n",
      "603                                                  nan\n",
      "604                                                  nan\n",
      "605                                                  nan\n",
      "Name: jd_rc_stem, Length: 606, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#stem context\n",
    "\n",
    "jd_rc_stem = []\n",
    "for i in df2['jd_rc']:\n",
    "    jd_stem = stemSentence(str(i))\n",
    "    jd_rc_stem.append(jd_stem.strip(' '))\n",
    "df2['jd_rc_stem']=jd_rc_stem\n",
    "print(df2['jd_rc_stem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count how many time each feature appear in context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     agil  ai  ajax  algorithm  amazon  analysi  analyt  angoss  angularj  \\\n",
      "0       0   0     0          0       0        0       0       0         0   \n",
      "1       0   0     0          0       0        1       0       0         0   \n",
      "2       0   0     0          0       0        0       1       0         0   \n",
      "3       0   0     0          0       0        1       1       0         0   \n",
      "4       0   0     0          0       0        0       0       0         0   \n",
      "5       1   1     0          1       0        1       1       0         0   \n",
      "6       0   1     0          0       0        0       0       0         0   \n",
      "7       0   0     0          0       0        0       0       0         0   \n",
      "8       0   1     0          1       0        0       0       0         0   \n",
      "9       0   0     0          0       0        1       1       0         0   \n",
      "10      0   0     0          1       0        1       0       0         0   \n",
      "11      0   0     0          0       0        0       0       0         0   \n",
      "12      0   0     0          0       0        0       0       0         0   \n",
      "13      0   0     0          0       0        0       0       0         0   \n",
      "14      0   0     0          0       0        0       1       0         0   \n",
      "15      0   0     0          0       0        1       1       0         0   \n",
      "16      0   0     0          0       0        0       0       0         0   \n",
      "17      0   0     0          0       0        0       0       0         0   \n",
      "18      0   0     0          0       0        0       1       0         0   \n",
      "19      0   0     0          0       0        0       0       0         0   \n",
      "20      0   0     0          0       0        0       0       0         0   \n",
      "21      0   1     0          1       0        1       1       0         0   \n",
      "22      0   0     0          0       0        1       1       0         0   \n",
      "23      0   0     0          0       0        0       0       0         0   \n",
      "24      0   0     0          1       0        0       1       0         0   \n",
      "25      0   0     0          0       0        0       1       0         0   \n",
      "26      0   0     0          0       0        0       0       0         0   \n",
      "27      0   0     0          0       0        0       0       0         0   \n",
      "28      0   0     0          0       0        0       0       0         0   \n",
      "29      0   0     0          0       0        0       0       0         0   \n",
      "..    ...  ..   ...        ...     ...      ...     ...     ...       ...   \n",
      "576     1   0     0          0       0        0       0       0         0   \n",
      "577     0   0     0          0       0        0       1       0         0   \n",
      "578     0   0     0          0       0        0       0       0         0   \n",
      "579     0   0     0          0       0        0       0       0         0   \n",
      "580     0   0     0          0       0        0       0       0         0   \n",
      "581     0   0     0          0       0        0       0       0         0   \n",
      "582     0   0     0          0       0        0       0       0         0   \n",
      "583     0   0     0          0       0        0       0       0         0   \n",
      "584     0   0     0          0       0        1       1       0         0   \n",
      "585     1   0     0          1       0        0       0       0         1   \n",
      "586     1   0     0          1       0        0       0       0         0   \n",
      "587     0   0     0          0       0        0       1       0         0   \n",
      "588     0   0     0          1       0        0       1       0         0   \n",
      "589     0   0     0          0       0        0       1       0         0   \n",
      "590     0   0     0          1       0        0       1       0         0   \n",
      "591     0   0     0          0       0        0       0       0         0   \n",
      "592     0   0     0          0       0        1       0       0         0   \n",
      "593     0   0     0          0       0        0       0       0         0   \n",
      "594     0   0     0          0       0        0       0       0         0   \n",
      "595     0   0     0          0       0        0       1       0         0   \n",
      "596     0   0     0          0       0        0       1       0         0   \n",
      "597     1   0     0          0       0        0       0       0         0   \n",
      "598     0   0     0          0       0        0       0       0         0   \n",
      "599     0   0     0          1       0        1       1       0         0   \n",
      "600     0   0     0          0       0        1       0       0         0   \n",
      "601     0   0     0          0       0        1       1       0         0   \n",
      "602     0   0     0          0       0        0       0       0         0   \n",
      "603     0   0     0          0       0        0       0       0         0   \n",
      "604     0   0     0          0       0        0       0       0         0   \n",
      "605     0   0     0          0       0        0       0       0         0   \n",
      "\n",
      "     apach   ...     vuej  warehous  watson  web  window  word  wsdl  xml  \\\n",
      "0        0   ...        0         1       0    0       0     0     0    0   \n",
      "1        0   ...        0         0       0    0       0     0     0    0   \n",
      "2        0   ...        0         0       0    0       0     0     0    0   \n",
      "3        0   ...        0         0       0    0       0     0     0    0   \n",
      "4        0   ...        0         0       0    0       0     0     0    0   \n",
      "5        0   ...        0         0       0    0       1     0     0    0   \n",
      "6        0   ...        0         0       0    0       0     0     0    0   \n",
      "7        0   ...        0         0       0    0       0     0     0    0   \n",
      "8        0   ...        0         0       0    0       0     0     0    0   \n",
      "9        0   ...        0         0       0    0       0     0     0    0   \n",
      "10       0   ...        0         0       0    0       0     0     0    0   \n",
      "11       0   ...        0         0       0    0       0     0     0    0   \n",
      "12       0   ...        0         0       0    0       0     1     0    0   \n",
      "13       0   ...        0         0       0    0       0     1     0    0   \n",
      "14       0   ...        0         0       0    0       0     0     0    0   \n",
      "15       0   ...        0         0       0    0       0     0     0    0   \n",
      "16       0   ...        0         0       0    0       0     0     0    0   \n",
      "17       0   ...        0         0       0    0       0     0     0    0   \n",
      "18       0   ...        0         0       0    1       0     0     1    0   \n",
      "19       0   ...        0         0       0    0       0     0     0    0   \n",
      "20       0   ...        0         0       0    0       1     0     0    0   \n",
      "21       0   ...        0         0       0    0       0     0     0    0   \n",
      "22       0   ...        0         0       0    0       0     0     0    0   \n",
      "23       0   ...        0         0       0    0       0     1     0    0   \n",
      "24       0   ...        0         0       0    0       0     0     0    0   \n",
      "25       0   ...        0         0       0    0       0     0     0    0   \n",
      "26       0   ...        0         0       0    0       0     0     0    0   \n",
      "27       0   ...        0         0       0    0       0     0     0    0   \n",
      "28       0   ...        0         0       0    0       0     0     0    0   \n",
      "29       0   ...        0         0       0    0       0     0     0    0   \n",
      "..     ...   ...      ...       ...     ...  ...     ...   ...   ...  ...   \n",
      "576      0   ...        0         0       0    0       0     0     0    0   \n",
      "577      0   ...        0         1       0    0       0     0     0    0   \n",
      "578      1   ...        0         1       0    0       0     0     0    0   \n",
      "579      0   ...        0         0       0    0       0     0     0    0   \n",
      "580      0   ...        0         0       0    0       0     0     0    0   \n",
      "581      0   ...        0         0       0    0       0     0     0    0   \n",
      "582      0   ...        0         0       0    0       0     0     0    0   \n",
      "583      0   ...        0         0       0    1       0     0     0    0   \n",
      "584      0   ...        0         1       0    0       0     0     0    0   \n",
      "585      0   ...        0         0       0    1       0     0     0    0   \n",
      "586      0   ...        0         0       0    0       0     0     0    1   \n",
      "587      0   ...        0         0       0    0       0     0     0    0   \n",
      "588      0   ...        0         0       0    0       0     0     0    0   \n",
      "589      0   ...        0         0       0    0       0     0     0    0   \n",
      "590      0   ...        0         0       0    0       0     0     0    0   \n",
      "591      0   ...        0         0       0    0       0     1     0    0   \n",
      "592      0   ...        0         1       0    0       0     0     0    0   \n",
      "593      0   ...        0         0       0    0       0     0     0    0   \n",
      "594      0   ...        0         0       0    0       0     0     0    0   \n",
      "595      0   ...        0         0       0    0       0     0     0    0   \n",
      "596      0   ...        0         0       0    0       0     0     0    0   \n",
      "597      0   ...        0         0       0    0       0     0     0    0   \n",
      "598      0   ...        0         1       0    1       0     0     0    0   \n",
      "599      1   ...        0         0       0    0       0     0     0    0   \n",
      "600      0   ...        0         0       0    0       0     0     0    0   \n",
      "601      0   ...        0         0       0    0       0     0     0    0   \n",
      "602      0   ...        0         0       0    0       0     0     0    0   \n",
      "603      0   ...        0         0       0    0       0     0     0    0   \n",
      "604      0   ...        0         0       0    0       0     0     0    0   \n",
      "605      0   ...        0         0       0    0       0     0     0    0   \n",
      "\n",
      "     yahoo  zookeep  \n",
      "0        0        0  \n",
      "1        0        0  \n",
      "2        0        1  \n",
      "3        0        0  \n",
      "4        0        0  \n",
      "5        0        0  \n",
      "6        0        0  \n",
      "7        0        0  \n",
      "8        0        0  \n",
      "9        0        0  \n",
      "10       0        0  \n",
      "11       0        0  \n",
      "12       0        0  \n",
      "13       0        0  \n",
      "14       0        0  \n",
      "15       0        0  \n",
      "16       0        0  \n",
      "17       0        0  \n",
      "18       0        0  \n",
      "19       0        0  \n",
      "20       0        0  \n",
      "21       0        0  \n",
      "22       1        0  \n",
      "23       0        0  \n",
      "24       0        0  \n",
      "25       0        0  \n",
      "26       0        0  \n",
      "27       0        0  \n",
      "28       0        0  \n",
      "29       0        0  \n",
      "..     ...      ...  \n",
      "576      0        0  \n",
      "577      0        0  \n",
      "578      0        0  \n",
      "579      0        0  \n",
      "580      0        0  \n",
      "581      0        0  \n",
      "582      0        0  \n",
      "583      0        0  \n",
      "584      0        0  \n",
      "585      0        0  \n",
      "586      0        0  \n",
      "587      0        0  \n",
      "588      0        0  \n",
      "589      0        0  \n",
      "590      0        0  \n",
      "591      0        0  \n",
      "592      0        0  \n",
      "593      0        0  \n",
      "594      0        0  \n",
      "595      0        0  \n",
      "596      1        0  \n",
      "597      0        0  \n",
      "598      0        0  \n",
      "599      0        0  \n",
      "600      0        0  \n",
      "601      0        0  \n",
      "602      0        0  \n",
      "603      0        0  \n",
      "604      0        0  \n",
      "605      0        0  \n",
      "\n",
      "[606 rows x 306 columns]\n",
      "['agil', 'ai', 'ajax', 'algorithm', 'amazon', 'analysi', 'analyt', 'angoss', 'angularj', 'apach', 'api', 'app', 'applic', 'artifici intellig', 'asp', 'athena', 'autom', 'aw', 'azur', 'bi', 'big data', 'bigqueri', 'block chain', 'bs', 'busi intellig', 'c', 'caff', 'cassandra', 'cdm', 'chatbot', 'ci', 'clean', 'clientcloud', 'clinic', 'cloud platform', 'cloudera', 'code', 'cogno', 'collabor', 'collect', 'comput scienc', 'crf', 'crm', 'cross function', 'csdn', 'css', 'cuda', 'd js', 'data', 'data analysi', 'data analyt', 'data center', 'data collect', 'data engin', 'data insight', 'data manag', 'data mart', 'data mine', 'data model', 'data pipelin', 'data platform', 'data process', 'data scienc', 'data scientist', 'data servic', 'data sourc', 'data statist', 'data system', 'data tool', 'data visual', 'data warehous', 'databas', 'dataset', 'db', 'debian', 'deep learn', 'design pattern', 'diagram', 'digit', 'distribut system', 'dj', 'django', 'dmp', 'docker', 'document', 'econom', 'ecosystem', 'elasticsearch', 'emr', 'engin', 'english', 'enterpris', 'equip', 'erp', 'etl', 'etl ms', 'excel', 'extract', 'facebook', 'financ', 'financi', 'flume', 'gcp', 'ggplot', 'git', 'github', 'global', 'glue', 'gohadoop', 'googl', 'googl analyt', 'googl cloud', 'gpu', 'hadoop ecosystem', 'hardwar', 'hbase', 'hdf', 'hive', 'html', 'http', 'imag process', 'imag recognit', 'impala', 'inform manag', 'innov', 'insight', 'intellig', 'iot', 'ip', 'java', 'javascript', 'jdbc', 'join', 'jqueri', 'js', 'json', 'jvm', 'kafka', 'kaggl', 'kera', 'kibana', 'kinesi', 'knime', 'lambda', 'larg scale', 'leadership', 'linux', 'll', 'logstash', 'machin learn', 'maintain', 'manag', 'manner', 'mapreduc', 'market', 'mart', 'math', 'mathemat', 'matlab', 'metric', 'micron', 'microsoft', 'mine', 'mine machin', 'minitab', 'ml', 'mobil', 'model', 'mongodb', 'monitor', 'ms', 'ms sql', 'mssql', 'multi', 'mysql', 'natur', 'natur languag', 'net', 'net python', 'network', 'network analysi', 'neural network', 'nlp', 'node js', 'nodej', 'nosql', 'numpi', 'od', 'odbc', 'offic', 'olap', 'open sourc', 'oper', 'optim', 'oracl', 'orang', 'osp', 'panda', 'perl', 'php', 'physic', 'pipelin', 'pl', 'pl sql', 'platform', 'plotli', 'pm', 'postgresql', 'powebi', 'power bi', 'powerpoint', 'predict', 'present', 'procedur', 'process', 'protocol', 'python', 'pytorch', 'qlikview', 'quantit', 'queri', 'r', 'rail', 'rapidmin', 'rdbm', 'react', 'redash', 'redi', 'redshift', 'relat', 'relat databas', 'report', 'rest', 'risk', 'rubi', 'rwd', 'sa', 'sa spss', 'salfrod', 'sap', 'scala', 'scalabl', 'scale', 'scikit', 'script', 'scrum', 'search', 'secur', 'serv', 'server', 'servic', 'shell', 'site', 'soap', 'social', 'social analysi', 'softwar', 'softwar develop', 'softwar engin', 'spark', 'spring', 'spss', 'sql', 'sql server', 'ssi', 'staff', 'stan', 'statist', 'statist experi', 'storag', 'store procedur', 'storm', 'strateg', 'strategi', 'stream', 'survey', 'svm', 'svn', 'system', 't sql', 'tableau', 'tensorflow', 'teradata', 'test', 'text mine', 'toeic', 'tune', 'ubuntu', 'ui', 'unix', 'user experi', 'ux', 'vba', 'visual', 'visual tool', 'vue', 'vuej', 'warehous', 'watson', 'web', 'window', 'word', 'wsdl', 'xml', 'yahoo', 'zookeep']\n"
     ]
    }
   ],
   "source": [
    "# tokenized -> remove chinese -> tfidf\n",
    "\n",
    "#jd_rc_list = df2['jd_rc'] #use raw data to count\n",
    "jd_rc_list_stem = df2['jd_rc_stem'] #use stemmed context to count\n",
    "\n",
    "\n",
    "#vectorizer = CountVectorizer(vocabulary = feature_names,binary = True, ngram_range = (1,2)) #unstemmed feature\n",
    "\n",
    "vectorizer = CountVectorizer(vocabulary = feature_stem,binary = True ,ngram_range = (1,2),min_df =1,token_pattern = r\"(?u)\\b\\w+\\b\") #stemmed feature\n",
    "\n",
    "#X = vectorizer.fit_transform(jd_rc_list).toarray() \n",
    "X = vectorizer.fit_transform(jd_rc_list_stem).toarray()\n",
    "\n",
    "word = vectorizer.get_feature_names()\n",
    "\n",
    "feature_count = pd.DataFrame(X, columns=word)\n",
    "\n",
    "\n",
    "print(feature_count)\n",
    "print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save file\n",
    "feature_count.to_csv(\"1128_104_job_feature_count_stemmed_reduced_1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
